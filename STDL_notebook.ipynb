{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spatial Transcriptomics Deep Learning (STDL) Project Notebook**\n",
    "\n",
    "> The notebook contains main experiments and examples of how to use the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Phase 1: Pre-processing and technical preparations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: **Assign GPU device and allow CUDA debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda debugging allowed\n"
     ]
    }
   ],
   "source": [
    "# the next 2 lines are to allow debugging with CUDA !\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  \n",
    "print(f'cuda debugging allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce RTX 2080 Ti\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7fdeb8348910>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CPU times: user 2.9 s, sys: 3.69 s, total: 6.59 s\n",
      "Wall time: 1.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "# NOTE: important !!!!!!\n",
    "# clearing out the cache before beginning\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: **Import the Pre-Process module**\n",
    "\n",
    "> `loadAndPreProcess` module contains methods to load the data files as pytorch and pandas objects, methods to preprocess the given data, and methods to create custom datasets from the preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO:</b> fill above line\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "%autoreload 2\n",
    "import loadAndPreProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: **Load pytorch dataset objects from the image folder**\n",
    "\n",
    "> loading regular and augmented datasets created from the given image folder with transformations.\n",
    "\n",
    "> Note: `augmentedImageFolder` is a custom dataset of imageFolder objects with different transformations (see code).\n",
    "\n",
    "> Note: `im_hight_and_width_size` will define the size to which the images in the folder will be resized to. their original size 176, and so if the number will be bigger, the images will be automaticaly upsampled in the `resize` (not sure by what method) - which means images might be \"pixelized\" / lower quality. The problem is, size 176 doesnt work with all models, so i had to increase the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_hight_and_width_size = 176  # values: 176 (doesnt work with inception) / 224 (doesnt work with inception) / 299 (works with inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 234 ms, sys: 27.2 ms, total: 261 ms\n",
      "Wall time: 265 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1/images\"\n",
    "imageFolder_train = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient1_train, im_hight_and_width_size)\n",
    "augmentedImageFolder_train = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient1_train, im_hight_and_width_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 21.7 ms, sys: 2.47 ms, total: 24.2 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2/images\"\n",
    "imageFolder_test = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient2_test, im_hight_and_width_size)\n",
    "# augmentedImageFolder_test = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient2_test, im_hight_and_width_size) # not needed for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: **Load pandas dataframe objects from the given mtx/tsv/csv files**\n",
    "\n",
    "> `matrix_dataframe` represents the gene expression count values of each sample for each gene\n",
    "\n",
    "> `features_dataframe` contains the names of all the genes\n",
    "\n",
    "> `barcodes_dataframe` contains the names of all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "adjusting matrix_dataframe\n",
      "V  finished working on matrix_dataframe\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "CPU times: user 1min 25s, sys: 1.24 s, total: 1min 27s\n",
      "Wall time: 1min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1\"\n",
    "matrix_dataframe_train, features_dataframe_train , barcodes_dataframe_train = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "adjusting matrix_dataframe\n",
      "V  finished working on matrix_dataframe\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "CPU times: user 1min 19s, sys: 1.07 s, total: 1min 20s\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2\"\n",
    "matrix_dataframe_test, features_dataframe_test , barcodes_dataframe_test = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: **Remove samples from the matrix dataframe with no matching images in the image folder**\n",
    "\n",
    "> Note: indices are being reset after this action, so a mapping of old to new column indices is returned: `column_mapping`.\n",
    "\n",
    "> Note: the dataframe is also reordered according to the images order in the image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting samples that dont have mathching images in the image folder from the dataframe ...\n",
      "V   done :)\n",
      "\n",
      "CPU times: user 26.9 s, sys: 1.19 s, total: 28.1 s\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_train, column_mapping_train = loadAndPreProcess.cut_samples_with_no_matching_image_and_reorder_df(matrix_df=matrix_dataframe_train, \n",
    "                                                                                                                    image_folder_of_the_df=imageFolder_train, \n",
    "                                                                                                                    barcodes_df=barcodes_dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting samples that dont have mathching images in the image folder from the dataframe ...\n",
      "V   done :)\n",
      "\n",
      "CPU times: user 33.6 s, sys: 828 ms, total: 34.4 s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_test, column_mapping_test = loadAndPreProcess.cut_samples_with_no_matching_image_and_reorder_df(matrix_df=matrix_dataframe_test, \n",
    "                                                                                                                  image_folder_of_the_df=imageFolder_test, \n",
    "                                                                                                                  barcodes_df=barcodes_dataframe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6: **Remove less-informative genes**\n",
    "\n",
    "> we define *less-informative* genes as genes with less than K counts over all samples\n",
    "\n",
    "> `Base_value` is a parameter for the user's choice\n",
    "\n",
    "> Note: indices are being reset after this action, so a mapping of old to new column indices is returned: `row_mapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for genes (rows) that contain less than B counts in both dataframes ...\n",
      "discarding relevant rows ...\n",
      "CPU times: user 45.3 s, sys: 2.48 s, total: 47.8 s\n",
      "Wall time: 47.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# begin by asserting that our dataframes have the same genes to begin with using the metadata of features_dataframe\n",
    "assert features_dataframe_train['gene_names'].equals(features_dataframe_test['gene_names'])\n",
    "\n",
    "Base_value = 10\n",
    "matrix_dataframe_train, matrix_dataframe_test, row_mapping = loadAndPreProcess.cut_genes_with_under_B_counts_from_train_and_test(matrix_dataframe_train, matrix_dataframe_test, Base_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7: **Normalize matrix_dataframe entries**\n",
    "\n",
    "> normaliztion will be performed on the remainning rows of the dataframe with the logic \"log 1P\"\n",
    "\n",
    "> This method Calculates log(1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 1.57 s, sys: 27.9 ms, total: 1.59 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_train = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 1.69 s, sys: 23.8 ms, total: 1.71 s\n",
      "Wall time: 1.71 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_test = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have performed all of the pre-processing actions on our matrix dataframes. (more pre-processing is still needed our datasets)\n",
    "\n",
    "> print some information regarding our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "print data regarding the reduced dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18077 entries, 0 to 18076\n",
      "Columns: 3813 entries, 0 to 3812\n",
      "dtypes: Sparse[float64, 0.0](3813)\n",
      "memory usage: 220.7 MB\n",
      "None\n",
      "   0         1     2     3     4         5     6     7         8     9     \\\n",
      "0   0.0  0.000000   0.0   0.0   0.0  0.693147   0.0   0.0  0.000000   0.0   \n",
      "1   0.0  1.098612   0.0   0.0   0.0  0.000000   0.0   0.0  0.693147   0.0   \n",
      "2   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   \n",
      "3   0.0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   \n",
      "4   0.0  0.693147   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   \n",
      "\n",
      "   ...  3803  3804      3805  3806  3807  3808  3809  3810  3811  3812  \n",
      "0  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3  ...   0.0   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4  ...   0.0   0.0  0.693147   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 3813 columns]\n",
      "\n",
      "min value in matrix_dataframe 0.0 max value in matrix_dataframe 8.62748154531036\n",
      "\n",
      "median value in matrix_dataframe 0.0 mean value in matrix_dataframe 0.32039982441271264\n",
      "\n",
      "number of different values in matrix_dataframe is  1087 \n",
      "\n",
      "list of 10 most common values in matrix_dataframe is: \n",
      "1: the value 0.0 appeared 49638925 times (constitutes 72.01603% of the matrix values)\n",
      "2: the value 0.6931471805599453 appeared 9701765 times (constitutes 14.07530% of the matrix values)\n",
      "3: the value 1.0986122886681096 appeared 3828178 times (constitutes 5.55391% of the matrix values)\n",
      "4: the value 1.3862943611198906 appeared 1865714 times (constitutes 2.70677% of the matrix values)\n",
      "5: the value 1.6094379124341003 appeared 1038719 times (constitutes 1.50697% of the matrix values)\n",
      "6: the value 1.791759469228055 appeared 636707 times (constitutes 0.92373% of the matrix values)\n",
      "7: the value 1.9459101490553132 appeared 420712 times (constitutes 0.61037% of the matrix values)\n",
      "8: the value 2.0794415416798357 appeared 294745 times (constitutes 0.42762% of the matrix values)\n",
      "9: the value 2.1972245773362196 appeared 215889 times (constitutes 0.31321% of the matrix values)\n",
      "10: the value 2.302585092994046 appeared 164262 times (constitutes 0.23831% of the matrix values)\n",
      "\n",
      "****\n",
      "\n",
      "\n",
      "print data regarding the reduced dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18077 entries, 0 to 18076\n",
      "Columns: 4015 entries, 0 to 4014\n",
      "dtypes: Sparse[float64, 0.0](4015)\n",
      "memory usage: 229.7 MB\n",
      "None\n",
      "       0     1     2     3         4     5     6         7     8     9     \\\n",
      "0  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0   \n",
      "1  0.000000   0.0   0.0   0.0  0.693147   0.0   0.0  0.693147   0.0   0.0   \n",
      "2  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0   \n",
      "3  0.000000   0.0   0.0   0.0  0.000000   0.0   0.0  0.000000   0.0   0.0   \n",
      "4  0.693147   0.0   0.0   0.0  0.693147   0.0   0.0  1.098612   0.0   0.0   \n",
      "\n",
      "   ...  4005      4006  4007  4008  4009  4010  4011  4012  4013  4014  \n",
      "0  ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "1  ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "2  ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "3  ...   0.0  0.693147   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "4  ...   0.0  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
      "\n",
      "[5 rows x 4015 columns]\n",
      "\n",
      "min value in matrix_dataframe 0.0 max value in matrix_dataframe 8.852807917623322\n",
      "\n",
      "median value in matrix_dataframe 0.0 mean value in matrix_dataframe 0.315108124458449\n",
      "\n",
      "number of different values in matrix_dataframe is  1172 \n",
      "\n",
      "list of 10 most common values in matrix_dataframe is: \n",
      "1: the value 0.0 appeared 52511911 times (constitutes 72.35123% of the matrix values)\n",
      "2: the value 0.6931471805599453 appeared 10229677 times (constitutes 14.09451% of the matrix values)\n",
      "3: the value 1.0986122886681096 appeared 3962322 times (constitutes 5.45931% of the matrix values)\n",
      "4: the value 1.3862943611198906 appeared 1903778 times (constitutes 2.62304% of the matrix values)\n",
      "5: the value 1.6094379124341003 appeared 1049475 times (constitutes 1.44597% of the matrix values)\n",
      "6: the value 1.791759469228055 appeared 641942 times (constitutes 0.88447% of the matrix values)\n",
      "7: the value 1.9459101490553132 appeared 424204 times (constitutes 0.58447% of the matrix values)\n",
      "8: the value 2.0794415416798357 appeared 297671 times (constitutes 0.41013% of the matrix values)\n",
      "9: the value 2.1972245773362196 appeared 217997 times (constitutes 0.30036% of the matrix values)\n",
      "10: the value 2.302585092994046 appeared 167120 times (constitutes 0.23026% of the matrix values)\n"
     ]
    }
   ],
   "source": [
    "import projectUtilities\n",
    "projectUtilities.printInfoAboutReducedDF(matrix_dataframe_train)\n",
    "print(\"\\n****\\n\")\n",
    "projectUtilities.printInfoAboutReducedDF(matrix_dataframe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8: **Create custom datasets**\n",
    "\n",
    "> Each custom dataset is tailored per task\n",
    "\n",
    "> there are four tasks: single gene prediction, k gene prediction, all gene prediction using NMF dim. reduction, all gene prediction using AE dim. reduction\n",
    "\n",
    "> For each of the above tasks 2 datasets were created:\n",
    "\n",
    ">> A Dataset created from the TRAIN data WITHOUT augmentation (without image transformations)\n",
    "\n",
    ">> A Dataset created from the TRAIN data WITH augmentation (with image transformations)\n",
    "\n",
    ">> A Dataset created from the TEST data WITHOUT augmentation (without image transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The chosen gene is CRISP3 and its variance is 1.3530372139065492\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "CPU times: user 857 ms, sys: 72 ms, total: 929 ms\n",
      "Wall time: 926 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## choose gene\n",
    "gene_name = 'CRISP3'  # was changed from 'BRCA1' because CRISP3 has the (almost) highest variance in both the train and test datasets.\n",
    "                      # NOTE: the gene 'CRISP3' is \"upregulated in certain types of prostate cancer\" according to\n",
    "                      #       https://www.genecards.org/cgi-bin/carddisp.pl?gene=CRISP3&keywords=rich\n",
    "                      # IMPORTANT ASSUMPTION: the chosen gene here actually appears in all reduced matrix dataframes (train and test) or the code might not work\n",
    "from projectUtilities import get_variance_of_gene\n",
    "gene_variance_value = get_variance_of_gene(gene_name=gene_name, matrix_df=matrix_dataframe_train, row_mapping=row_mapping, features_df=features_dataframe_train)\n",
    "print(f'The chosen gene is {gene_name} and its variance is {gene_variance_value}')\n",
    "\n",
    "## create datasets\n",
    "custom_DS_SingleValuePerImg_augmented = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=augmentedImageFolder_train, \n",
    "                                                               matrix_dataframe=matrix_dataframe_train, \n",
    "                                                               features_dataframe=features_dataframe_train, \n",
    "                                                               barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                               column_mapping=column_mapping_train,\n",
    "                                                               row_mapping=row_mapping,\n",
    "                                                               chosen_gene_name=gene_name)\n",
    "custom_DS_SingleValuePerImg_test = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder_test, \n",
    "                                                               matrix_dataframe=matrix_dataframe_test, \n",
    "                                                               features_dataframe=features_dataframe_test, \n",
    "                                                               barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                               column_mapping=column_mapping_test,\n",
    "                                                               row_mapping=row_mapping,\n",
    "                                                               chosen_gene_name=gene_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance` class, K genes with the highest variance are chosen from matrix_dataframe, and they are the only genes that are kept for training and testing purposes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "the K genes with the highest variance are:\n",
      "      gene_names  variance\n",
      "15326      COX6C  1.384259\n",
      "10975     CRISP3  1.353037\n",
      "6665        CPB1  1.328052\n",
      "20428        MGP  1.309196\n",
      "13994     TCEAL4  1.237330\n",
      "9549      CXCL14  1.215041\n",
      "5098      IGFBP5  1.177371\n",
      "18155      CCND1  1.167686\n",
      "11978       AGR2  1.163414\n",
      "20840       KRT8  1.158179\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "the K genes with the highest variance are:\n",
      "      gene_names  variance\n",
      "10975     CRISP3  1.301761\n",
      "6665        CPB1  1.259807\n",
      "9549      CXCL14  1.217983\n",
      "32395      IGLC2  1.125526\n",
      "4026        IGKC  1.107278\n",
      "20428        MGP  1.096459\n",
      "23764      IGHG1  0.993734\n",
      "23765      IGHG3  0.987250\n",
      "13994     TCEAL4  0.985546\n",
      "11978       AGR2  0.955655\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "CPU times: user 16.2 s, sys: 1.78 s, total: 18 s\n",
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "\n",
    "custom_DS_KGenesWithHighestVariance_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           row_mapping=row_mapping,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           row_mapping=row_mapping,                                                                                                                  \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_LatentTensor_NMF` class, an NMF decompositionis performed on the matrix_dataframe object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "CPU times: user 19min 5s, sys: 8min 47s, total: 27min 52s\n",
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> \n",
    "<ul>\n",
    "  <li>first we create a dataset from `matrix_dataframe_train` to feed our AEnet.</li>\n",
    "  <li>Then we create our AEnet and train it.</li>\n",
    "  <li>Finally, we create our `custom_DS_LatentTensor_AE` class, in which the Autoencoder network will be saved.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_matrix_df = loadAndPreProcess.STDL_Dataset_matrix_df_for_AE_init(matrix_dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "iteration 1 of 3 epochs\n",
      "iteration 2 of 3 epochs\n",
      "iteration 3 of 3 epochs\n",
      "finished all epochs !                                         \n",
      "which means, that this model is now trained.\n",
      "plotting the loss convergence for the training of this model: \n",
      "\n",
      "----- entered function plot_loss_convergence -----\n",
      "\n",
      "----- finished function plot_loss_convergence -----\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n",
      "CPU times: user 3min 9s, sys: 25.7 s, total: 3min 35s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from executionModule import get_Trained_AEnet\n",
    "k = 10\n",
    "AEnet = get_Trained_AEnet(dataset_from_matrix_df=dataset_from_matrix_df, z_dim=k, num_of_epochs=3, device=device)  # NOTE: tweak num_of_epochs as wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "CPU times: user 936 ms, sys: 736 ms, total: 1.67 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           AEnet=AEnet,                                                                                                            \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           AEnet=AEnet,                                                                                                       \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9: prepare for the next phases in which the experiments are executed\n",
    "\n",
    "> import `executionModule` which contains the experiments, training methods, and testing methods\n",
    "\n",
    "> create `hyperparameters` dictionary which will contain all of the hyper-parameters for our experiments (note - user can change these later)\n",
    "\n",
    "> create `model_list` that will hold all the names for the models that will be used (only 3 models for now, as can be seen below). the models are:\n",
    "\n",
    ">> `BasicConvNet` model\n",
    "\n",
    ">> `DensetNet121` model\n",
    "\n",
    ">> `Inception_V3` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> change the hyper-parameters below with caution if needed !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import executionModule\n",
    "\n",
    "# define hyperparameters for the TRAINING of the models (NOT the testing phases of the experiments)\n",
    "hyperparameters = dict()\n",
    "hyperparameters['batch_size'] = 30\n",
    "hyperparameters['max_alowed_number_of_batches'] = 20 #<--------------------------change to inf or 99999. anythin below 1220 will cut some batches ... this is only used to speed up training\n",
    "hyperparameters['precent_of_dataset_allocated_for_training'] = 0.8\n",
    "hyperparameters['learning_rate'] = 1e-4\n",
    "hyperparameters['momentum'] = 0.9\n",
    "hyperparameters['num_of_epochs'] = 2 #<------------------------------------------change to 5 at least\n",
    "hyperparameters['num_workers'] = 2 #<---- NOTE: default is 0, means everything happens serially. testing 2 now !.\n",
    "                                   # see: https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading\n",
    "\n",
    "# define hyperparameters for BsicConvNet\n",
    "hyperparameters['channels'] = [32, 32, 64, 64] \n",
    "hyperparameters['num_of_convolution_layers'] = len(hyperparameters['channels'])\n",
    "hyperparameters['hidden_dims'] = [100, 100]\n",
    "hyperparameters['num_of_hidden_layers'] = len(hyperparameters['hidden_dims'])\n",
    "hyperparameters['pool_every'] = 99999\n",
    "\n",
    "# add the chosen single gene's index to the hyperparameters\n",
    "from projectUtilities import get_index_of_gene_by_name\n",
    "hyperparameters['gene_name'] = gene_name\n",
    "hyperparameters['geneRowIndexIn_Reduced_Train_matrix_df'], hyperparameters['geneRowIndexIn_Original_Train_matrix_df'] = get_index_of_gene_by_name(gene_name=gene_name, matrix_df=matrix_dataframe_train, row_mapping=row_mapping, features_df=features_dataframe_train)\n",
    "hyperparameters['geneRowIndexIn_Reduced_Test_matrix_df'], hyperparameters['geneRowIndexIn_Original_Test_matrix_df'] = get_index_of_gene_by_name(gene_name=gene_name, matrix_df=matrix_dataframe_test, row_mapping=row_mapping, features_df=features_dataframe_test)\n",
    "\n",
    "# list of all models used\n",
    "model_list = []\n",
    "model_list.append('BasicConvNet')\n",
    "model_list.append('DensetNet121')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We add the code before the plots to show them correctly `%matplotlib inline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> In each experiment, the model is trained with the augmented train dataset, and then tested on the test dataset\n",
    "    (NMF and AE experiments also test on the regular train dataset after training is done)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Single Gene Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "executionModule.runExperiment(ds_train=custom_DS_SingleValuePerImg_augmented, \n",
    "                                ds_test=custom_DS_SingleValuePerImg_test,\n",
    "                                hyperparams=hyperparameters, \n",
    "                                device=device, \n",
    "                                model_name='BasicConvNet', \n",
    "                                dataset_name='single_gene ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# executionModule.runExperiment(ds_train=custom_DS_SingleValuePerImg_augmented, \n",
    "#                                 ds_test=custom_DS_SingleValuePerImg_test,\n",
    "#                                 hyperparams=hyperparameters, \n",
    "#                                 device=device, \n",
    "#                                 model_name='DensetNet121', \n",
    "#                                 dataset_name='single_gene ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: K genes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "executionModule.runExperiment(ds_train=custom_DS_KGenesWithHighestVariance_augmented, \n",
    "                                ds_test=custom_DS_KGenesWithHighestVariance_test,\n",
    "                                hyperparams=hyperparameters, \n",
    "                                device=device, \n",
    "                                model_name='BasicConvNet', \n",
    "                                dataset_name='k_genes ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# executionModule.runExperiment(ds_train=custom_DS_KGenesWithHighestVariance_augmented, \n",
    "#                                 ds_test=custom_DS_KGenesWithHighestVariance_test,\n",
    "#                                 hyperparams=hyperparameters, \n",
    "#                                 device=device, \n",
    "#                                 model_name='DensetNet121', \n",
    "#                                 dataset_name='k_genes ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: All genes prediction - using dimensionality reduction techniques\n",
    "\n",
    "### 4.1: Prediction using dimensionality reduction technique NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperiment -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "NOTE: in order to speed up training (while damaging accuracy) the number of batches per epoch was reduced from 1016 to 20\n",
      "****** begin training ******\n",
      "iteration 1 of 2 epochs\n",
      "iteration 2 of 2 epochs\n",
      "finished all epochs !                                         \n",
      "which means, that this model is now trained.\n",
      "plotting the loss convergence for the training of this model: \n",
      "\n",
      "----- entered function plot_loss_convergence -----\n",
      "\n",
      "----- finished function plot_loss_convergence -----\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "## perform on TRAIN data ##\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "matrix comparsions on all genes ...\n",
      "distance between M_truth, M_pred: 7.019420702803787e-05\n",
      "distance between M_truth, Baseline: 3.8139701375500744e-05\n",
      "distance between M_pred, Baseline: 5.8892469566212774e-05\n",
      "results plot & vector comparsions on the chosen single gene ...\n",
      "distance between M_truth, M_pred: 0.022736576412631607\n",
      "distance between M_truth, Baseline: 0.007951409888908594\n",
      "distance between M_pred, Baseline: 0.02143425383701413\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n",
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n",
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "## perform on TEST data ##\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "matrix comparsions on all genes ...\n",
      "distance between M_truth, M_pred: 6.394324705555912e-05\n",
      "distance between M_truth, Baseline: 4.673228895567077e-05\n",
      "distance between M_pred, Baseline: 4.353310511258435e-05\n",
      "results plot & vector comparsions on the chosen single gene ...\n",
      "distance between M_truth, M_pred: 0.021120166425855246\n",
      "distance between M_truth, Baseline: 0.018084382932968556\n",
      "distance between M_pred, Baseline: 0.011342300312011215\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n",
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "----- finished function runExperiment -----\n",
      "CPU times: user 2min 29s, sys: 1min 21s, total: 3min 50s\n",
      "Wall time: 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "executionModule.runExperiment(ds_train=custom_DS_LatentTensor_NMF_augmented, \n",
    "                                ds_test=custom_DS_LatentTensor_NMF_test,\n",
    "                                hyperparams=hyperparameters, \n",
    "                                device=device, \n",
    "                                model_name='BasicConvNet', \n",
    "                                dataset_name='NMF ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# executionModule.runExperiment(ds_train=custom_DS_LatentTensor_NMF_augmented, \n",
    "#                                 ds_test=custom_DS_LatentTensor_NMF_test,\n",
    "#                                 hyperparams=hyperparameters, \n",
    "#                                 device=device, \n",
    "#                                 model_name='DensetNet121', \n",
    "#                                 dataset_name='NMF ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Prediction using dimensionality reduction technique AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperiment -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "NOTE: in order to speed up training (while damaging accuracy) the number of batches per epoch was reduced from 1016 to 20\n",
      "****** begin training ******\n",
      "finished all epochs !                                         \n",
      "which means, that this model is now trained.\n",
      "plotting the loss convergence for the training of this model: \n",
      "\n",
      "----- entered function plot_loss_convergence -----\n",
      "\n",
      "----- finished function plot_loss_convergence -----\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "## perform on TRAIN data ##\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_AE_DS -----\n",
      "\n",
      "----- finished function getFullDimsPrediction_with_AE_DS -----\n",
      "\n",
      "----- entered function getAutoEncoder_M_fast_reconstruction -----\n",
      "batch 3813 of 3813 batches\n",
      "----- finished function getAutoEncoder_M_fast_reconstruction -----\n",
      "matrix comparsions on all genes ...\n",
      "distance between M_truth, M_pred: 7.581811000105335e-05\n",
      "distance between M_truth, Baseline: 3.869205643514623e-05\n",
      "distance between M_pred, Baseline: 6.670289323077195e-05\n",
      "results plot & vector comparsions on the chosen single gene ...\n",
      "distance between M_truth, M_pred: 0.02567137680121934\n",
      "distance between M_truth, Baseline: 0.01123968516586411\n",
      "distance between M_pred, Baseline: 0.02278620822205182\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n",
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy.rubin/STDLproject/projectUtilities.py:380: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(8,8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "## perform on TEST data ##\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_AE_DS -----\n",
      "\n",
      "----- finished function getFullDimsPrediction_with_AE_DS -----\n",
      "matrix comparsions on all genes ...\n",
      "distance between M_truth, M_pred: 7.301726689644475e-05\n",
      "distance between M_truth, Baseline: 4.673228895567077e-05\n",
      "distance between M_pred, Baseline: 5.6236015651385795e-05\n",
      "results plot & vector comparsions on the chosen single gene ...\n",
      "distance between M_truth, M_pred: 0.023631136021437987\n",
      "distance between M_truth, Baseline: 0.018084382932968556\n",
      "distance between M_pred, Baseline: 0.017010916456694482\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ScatterComparison -----\n",
      "\n",
      "----- entered function plot_SingleGene_PredAndTrue_ColorVisualisation -----\n",
      "finished preparing the plots, now just need to show on screen ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/roy.rubin/STDLproject/projectUtilities.py:380: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  plt.figure(figsize=(8,8))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- finished function plot_Single_Gene_PredAndTrue -----\n",
      "\n",
      "----- finished function runExperiment -----\n",
      "CPU times: user 9min 12s, sys: 8min 22s, total: 17min 35s\n",
      "Wall time: 17min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "hyperparameters['num_of_epochs'] = 0\n",
    "\n",
    "executionModule.runExperiment(ds_train=custom_DS_LatentTensor_AE_augmented, \n",
    "                                ds_test=custom_DS_LatentTensor_AE_test,\n",
    "                                hyperparams=hyperparameters, \n",
    "                                device=device, \n",
    "                                model_name='BasicConvNet', \n",
    "                                dataset_name='AE ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# executionModule.runExperiment(ds_train=custom_DS_LatentTensor_AE_augmented, \n",
    "#                                 ds_test=custom_DS_LatentTensor_AE_test,\n",
    "#                                 hyperparams=hyperparameters, \n",
    "#                                 device=device, \n",
    "#                                 model_name='DensetNet121', \n",
    "#                                 dataset_name='AE ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note:</b> below this - everything is a testing block\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04204044 0.82069342]\n",
      " [0.70913043 0.47583602]\n",
      " [0.19047911 0.45901468]]\n",
      "***\n",
      "3\n",
      "***\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "temp = np.random.rand(3,2)\n",
    "print(temp)\n",
    "print(\"***\")\n",
    "print(len(temp))\n",
    "print(\"***\")\n",
    "print(temp.size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.savefig(f'old_files/testimg.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]]\n",
      "***\n",
      "[6. 7. 8.]\n",
      "***\n",
      "[ 1.  4.  7. 10. 13.]\n",
      "***\n",
      "[[ 1.]\n",
      " [ 4.]\n",
      " [ 7.]\n",
      " [10.]\n",
      " [13.]]\n",
      "***\n",
      "[[ 1.  1.  1.]\n",
      " [ 4.  4.  4.]\n",
      " [ 7.  7.  7.]\n",
      " [10. 10. 10.]\n",
      " [13. 13. 13.]]\n"
     ]
    }
   ],
   "source": [
    "data = np.arange(15).reshape((5,3))\n",
    "print(data)\n",
    "print(\"***\")\n",
    "print(np.average(data, axis=0))\n",
    "print(\"***\")\n",
    "print(np.average(data, axis=1))\n",
    "print(\"***\")\n",
    "print(np.average(data, axis=1).reshape(-1,1))\n",
    "print(\"***\")\n",
    "\n",
    "print(np.tile(A=np.average(data, axis=1).reshape(-1,1), reps=(1,3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## das sa dsadas asd\n",
    "\n",
    "## sad asdawafdawf\n",
    "print('hi')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
