{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spatial Transcriptomics Deep Learning (STDL) Project Notebook**\n",
    "\n",
    "> The notebook contains main experiments and examples of how to use the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Phase 1: Pre-processing and technical preparations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: **Assign GPU device and allow CUDA debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda debugging allowed\n"
     ]
    }
   ],
   "source": [
    "# the next 2 lines are to allow debugging with CUDA !\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  \n",
    "print(f'cuda debugging allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce RTX 2080 Ti\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7f9ed1eeefd0>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CPU times: user 2.18 s, sys: 3.98 s, total: 6.16 s\n",
      "Wall time: 9.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "# NOTE: important !!!!!!\n",
    "# clearing out the cache before beginning\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: **Import the Pre-Process module**\n",
    "\n",
    "> `loadAndPreProcess` module contains methods to load the data files as pytorch and pandas objects, methods to preprocess the given data, and methods to create custom datasets from the preprocessed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO:</b> fill above line\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "%autoreload 2\n",
    "import loadAndPreProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: **Load pytorch dataset objects from the image folder**\n",
    "\n",
    "> loading regular and augmented datasets created from the given image folder with transformations.\n",
    "\n",
    "> Note: `augmentedImageFolder` is a custom dataset of imageFolder objects with different transformations (see code).\n",
    "\n",
    "> Note: `im_hight_and_width_size` will define the size to which the images in the folder will be resized to. their original size 176, and so if the number will be bigger, the images will be automaticaly upsampled in the `resize` (not sure by what method) - which means images might be \"pixelized\" / lower quality. The problem is, size 176 doesnt work with all models, so i had to increase the size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_hight_and_width_size = 176  # values: 176 (doesnt work with inception) / 224 (doesnt work with inception) / 299 (works with inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 212 ms, sys: 28.6 ms, total: 240 ms\n",
      "Wall time: 257 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1/images\"\n",
    "imageFolder_train = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient1_train, im_hight_and_width_size)\n",
    "augmentedImageFolder_train = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient1_train, im_hight_and_width_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 55.8 ms, sys: 115 ms, total: 171 ms\n",
      "Wall time: 1.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2/images\"\n",
    "imageFolder_test = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient2_test, im_hight_and_width_size)\n",
    "# augmentedImageFolder_test = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient2_test, im_hight_and_width_size) # not needed for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: **Load pandas dataframe objects from the given mtx/tsv/csv files**\n",
    "\n",
    "> `matrix_dataframe` represents the gene expression count values of each sample for each gene\n",
    "\n",
    "> `features_dataframe` contains the names of all the genes\n",
    "\n",
    "> `barcodes_dataframe` contains the names of all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "adjusting matrix_dataframe\n",
      "V  finished working on matrix_dataframe\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "CPU times: user 1min 53s, sys: 2.1 s, total: 1min 55s\n",
      "Wall time: 2min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1\"\n",
    "matrix_dataframe_train, features_dataframe_train , barcodes_dataframe_train = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "adjusting matrix_dataframe\n",
      "V  finished working on matrix_dataframe\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "CPU times: user 1min 45s, sys: 1.87 s, total: 1min 47s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2\"\n",
    "matrix_dataframe_test, features_dataframe_test , barcodes_dataframe_test = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: **Remove samples from the matrix dataframe with no matching images in the image folder**\n",
    "\n",
    "> Note: indices are being reset after this action, so a mapping of old to new column indices is returned: `column_mapping`.\n",
    "\n",
    "> Note: the dataframe is also reordered according to the images order in the image folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting samples that dont have mathching images in the image folder from the dataframe ...\n",
      "V   done :)\n",
      "\n",
      "CPU times: user 42.4 s, sys: 2.11 s, total: 44.5 s\n",
      "Wall time: 46.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_train, column_mapping_train = loadAndPreProcess.cut_samples_with_no_matching_image_and_reorder_df(matrix_df=matrix_dataframe_train, \n",
    "                                                                                                                    image_folder_of_the_df=imageFolder_train, \n",
    "                                                                                                                    barcodes_df=barcodes_dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting samples that dont have mathching images in the image folder from the dataframe ...\n",
      "V   done :)\n",
      "\n",
      "CPU times: user 42.2 s, sys: 1.83 s, total: 44 s\n",
      "Wall time: 45.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_test, column_mapping_test = loadAndPreProcess.cut_samples_with_no_matching_image_and_reorder_df(matrix_df=matrix_dataframe_test, \n",
    "                                                                                                                  image_folder_of_the_df=imageFolder_test, \n",
    "                                                                                                                  barcodes_df=barcodes_dataframe_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6: **Remove less-informative genes**\n",
    "\n",
    "> we define *less-informative* genes as genes with less than K counts over all samples\n",
    "\n",
    "> `Base_value` is a parameter for the user's choice\n",
    "\n",
    "> Note: indices are being reset after this action, so a mapping of old to new column indices is returned: `row_mapping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# Base_value = 10\n",
    "# matrix_dataframe_train, row_mapping_train = loadAndPreProcess.cut_genes_with_under_B_counts(matrix_dataframe_train, Base_value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# Base_value = 1\n",
    "# matrix_dataframe_test, row_mapping_test = loadAndPreProcess.cut_genes_with_under_B_counts(matrix_dataframe_test, Base_value) \n",
    "# #TODO: note that this actually is not really needed, but it is to not change the functions inside this class to adjust to the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for genes (rows) that contain less than B counts in both dataframes ...\n",
      "discarding relevant rows ...\n",
      "CPU times: user 53.8 s, sys: 2.88 s, total: 56.7 s\n",
      "Wall time: 59.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# begin by asserting that our dataframes have the same genes to begin with using the metadata of features_dataframe\n",
    "assert features_dataframe_train['gene_names'].equals(features_dataframe_test['gene_names'])\n",
    "\n",
    "Base_value = 10\n",
    "matrix_dataframe_train, matrix_dataframe_test, row_mapping = loadAndPreProcess.cut_genes_with_under_B_counts_from_train_and_test(matrix_dataframe_train, matrix_dataframe_test, Base_value) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7: **Normalize matrix_dataframe entries**\n",
    "\n",
    "> normaliztion will be performed on the remainning rows of the dataframe with the logic \"log 1P\"\n",
    "\n",
    "> This method Calculates log(1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 1.87 s, sys: 87.2 ms, total: 1.96 s\n",
      "Wall time: 2.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_train = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 2.18 s, sys: 191 ms, total: 2.37 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_test = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8: **Create custom datasets**\n",
    "\n",
    "> Each custom dataset is tailored per task\n",
    "\n",
    "> there are four tasks: single gene prediction, k gene prediction, all gene prediction using NMF dim. reduction, all gene prediction using AE dim. reduction\n",
    "\n",
    "> For each of the above tasks 2 datasets were created:\n",
    "\n",
    ">> A Dataset created from the TRAIN data WITHOUT augmentation (without image transformations)\n",
    "\n",
    ">> A Dataset created from the TRAIN data WITH augmentation (with image transformations)\n",
    "\n",
    ">> A Dataset created from the TEST data WITHOUT augmentation (without image transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "CPU times: user 953 ms, sys: 119 ms, total: 1.07 s\n",
      "Wall time: 1.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gene_name = 'MKI67'\n",
    "custom_DS_SingleValuePerImg = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder_train, \n",
    "                                                               matrix_dataframe=matrix_dataframe_train, \n",
    "                                                               features_dataframe=features_dataframe_train, \n",
    "                                                               barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                               column_mapping=column_mapping_train,\n",
    "                                                               row_mapping=row_mapping,\n",
    "                                                               chosen_gene_name=gene_name)\n",
    "custom_DS_SingleValuePerImg_augmented = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=augmentedImageFolder_train, \n",
    "                                                               matrix_dataframe=matrix_dataframe_train, \n",
    "                                                               features_dataframe=features_dataframe_train, \n",
    "                                                               barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                               column_mapping=column_mapping_train,\n",
    "                                                               row_mapping=row_mapping,\n",
    "                                                               chosen_gene_name=gene_name)\n",
    "custom_DS_SingleValuePerImg_test = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder_test, \n",
    "                                                               matrix_dataframe=matrix_dataframe_test, \n",
    "                                                               features_dataframe=features_dataframe_test, \n",
    "                                                               barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                               column_mapping=column_mapping_test,\n",
    "                                                               row_mapping=row_mapping,\n",
    "                                                               chosen_gene_name=gene_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance` class, K genes with the highest variance are chosen from matrix_dataframe, and they are the only genes that are kept for training and testing purposes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "CPU times: user 27.5 s, sys: 2.4 s, total: 29.9 s\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_KGenesWithHighestVariance = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_LatentTensor_NMF` class, an NMF decompositionis performed on the matrix_dataframe object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "CPU times: user 24min 24s, sys: 16min 35s, total: 41min\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_NMF = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> \n",
    "<ul>\n",
    "  <li>first we create a dataset from `matrix_dataframe_train` to feed our AEnet.</li>\n",
    "  <li>Then we create our AEnet and train it.</li>\n",
    "  <li>Finally, we create our `custom_DS_LatentTensor_AE` class, in which the Autoencoder network will be saved.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_from_matrix_df = loadAndPreProcess.STDL_Dataset_matrix_df_for_AE_init(matrix_dataframe_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 3813 of 3813 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0127635532990098 max loss 1.0060787200927734\n",
      "               average loss 0.1140093217273393\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 3813 of 3813 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.011536810547113419 max loss 0.22284650802612305\n",
      "               average loss 0.10551176326500324\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 3813 of 3813 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.011026603169739246 max loss 0.20367717742919922\n",
      "               average loss 0.10407850408568536\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from executionModule import get_Trained_AEnet\n",
    "k = 10\n",
    "AEnet = get_Trained_AEnet(dataset_from_matrix_df=dataset_from_matrix_df, z_dim=k, num_of_epochs=3, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "CPU times: user 1.8 s, sys: 19.2 s, total: 21 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_AE = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           AEnet=AEnet,\n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_train, \n",
    "                                                                           AEnet=AEnet,                                                                                                            \n",
    "                                                                           column_mapping=column_mapping_train,\n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_dataframe=barcodes_dataframe_test, \n",
    "                                                                           AEnet=AEnet,                                                                                                       \n",
    "                                                                           column_mapping=column_mapping_test,\n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9: prepare for the next phases in which the experiments are executed\n",
    "\n",
    "> import `executionModule` which contains the experiments, training methods, and testing methods\n",
    "\n",
    "> create `hyperparameters` dictionary which will contain all of the hyper-parameters for our experiments (note - user can change these later)\n",
    "\n",
    "> create `model_list` that will hold all the names for the models that will be used (only 3 models for now, as can be seen below). the models are:\n",
    "\n",
    ">> `BasicConvNet` model\n",
    "\n",
    ">> `DensetNet121` model\n",
    "\n",
    ">> `Inception_V3` model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> change the hyper-parameters below with caution if needed !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import executionModule\n",
    "\n",
    "# define hyperparameters for the experiments\n",
    "hyperparameters = dict()\n",
    "hyperparameters['batch_size'] = 25\n",
    "hyperparameters['max_alowed_number_of_batches'] = 99999\n",
    "hyperparameters['precent_of_dataset_allocated_for_training'] = 0.8\n",
    "hyperparameters['learning_rate'] = 1e-4\n",
    "hyperparameters['momentum'] = 0.9\n",
    "hyperparameters['num_of_epochs'] = 3\n",
    "\n",
    "# define hyperparameters for BsicConvNet\n",
    "hyperparameters['channels'] = [32] \n",
    "hyperparameters['num_of_convolution_layers'] = len(hyperparameters['channels'])\n",
    "hyperparameters['hidden_dims'] = [100]\n",
    "hyperparameters['num_of_hidden_layers'] = len(hyperparameters['hidden_dims'])\n",
    "hyperparameters['pool_every'] = 99999\n",
    "\n",
    "# list of all models used\n",
    "model_list = []\n",
    "model_list.append('BasicConvNet')\n",
    "model_list.append('DensetNet121')\n",
    "# model_list.append('Inception_V3')  #TODO: still need to sort out input image size... !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note:</b> inception_v3 model isnt sorted out yet... gives\n",
    "    RuntimeError: Calculated padded input size per channel: (2 x 2). Kernel size: (5 x 5). Kernel size can't be greater than actual input size\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> creating an assisting method for our testing that will time each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_loop(ds_train, ds_test, phase_name):\n",
    "    for model_name in model_list:\n",
    "        print(f'\\nstarting experiment **{model_name}**\\n')\n",
    "        %time executionModule.runExperiment(ds_train=ds_train, ds_test=ds_test, hyperparams=hyperparameters, device=device, model_name=model_name, dataset_name=phase_name)\n",
    "        print(f'\\nfinished experiment {model_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Single Gene Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 4.1480508997154075\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.24410368943292843\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.21795833022578767\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getSingleDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015,)  ~  M_truth.shape (4015,)\n",
      "\n",
      "----- finished function getSingleDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 34.43702292482944\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 2min 25s, sys: 22 s, total: 2min 47s\n",
      "Wall time: 4min 20s\n",
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.24790029399293034\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.2367228662203017\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.23032422461792043\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getSingleDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015,)  ~  M_truth.shape (4015,)\n",
      "\n",
      "----- finished function getSingleDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 32.38077006082694\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 35min 51s, sys: 8min 32s, total: 44min 23s\n",
      "Wall time: 48min 9s\n",
      "\n",
      "finished experiment DensetNet121\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_SingleValuePerImg ,ds_test=custom_DS_SingleValuePerImg_test ,phase_name='single_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.5842790643211271\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.23884593719219574\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.22119824710439462\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getSingleDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015,)  ~  M_truth.shape (4015,)\n",
      "\n",
      "----- finished function getSingleDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 35.42027152930368\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 16min 45s, sys: 2min 34s, total: 19min 20s\n",
      "Wall time: 24min 53s\n",
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.23365755856159282\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.22478519607274258\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.21885756436185758\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getSingleDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015,)  ~  M_truth.shape (4015,)\n",
      "\n",
      "----- finished function getSingleDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 33.38338891643095\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 1h 29min 1s, sys: 17min 24s, total: 1h 46min 26s\n",
      "Wall time: 1h 59min 21s\n",
      "\n",
      "finished experiment DensetNet121\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaIAAAEmCAYAAAAgKpShAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd3hUZfbA8e8htABBqtIUXAsLSJVFEQv81MUCSHVhEQWliLIiIopdVkQUVFBQVNaugA0QZUWUpYiF3lFEQAkgIL0Lyfn98d6EyTCTTJKZ3JTzeZ48mbn3zr3nztyZc8t7zyuqijHGGOOXQn4HYIwxpmCzRGSMMcZXloiMMcb4yhKRMcYYX1kiMsYY4ytLRMYYY3xliSgXEpHZItIzSvMSEXlDRPaIyIJozDM3EJH/isgtObi85iKSmFPLMyeJiIrIuX7HkRuJyJsiMtTvOLLLElEGRGSTiBwRkYMi8rv3wZfKweV3F5FvsjGLS4GrgWqq2iRKYflOVa9V1bf8jiMSeSGJeduZishzQcPbesPfzOD1NbzpCmczjizvhIlIF+/7KkHDC4vIDhFp5T1/UEQ2et/pRBGZlM48N4nInyJSIWj4Mm99a2QlVpOWJaLItFbVUkADoCHwgM/xZEZ1YJOqHvI7kGjwjvBsu42NX4B/BCWTm4F10Zh5dpNUBCYDZYArgoZfAyjwhXcU3Q24yvtONwa+zmC+G4EuKU9EpC4QH62gA+Yb6/cn17IvdCao6u/ADFxCAkBELhaRb0Vkr4gsF5HmAeO6i8gGETng7YF19YY/LiLvBkwXcm9SRGoB44Cm3t7b3lBxiUgVEflURHaLyHoR6eUNvw0YH/D6IWFe30tE1npxrhGRRinL9/ZQ94rIahFpE/CaN0XkJe8U2UERmS8ilURklHca8EcRaRgw/SYRecCb/x7vdGFxb1xZEflMRHZ64z4TkWoBr50tIk+KyHzgMPCXwD1nETlXROaIyD4R+SNwD1dELhGRhd64hSJySdB8n/BiPyAiXwbv+YZ4rx70lrEp5fP0hhcTkZEi8puIbBeRcSISLyIlgf8CVbz36aD3eR1JWZaIPCwiJ0SktPd8qIiMSm++Actt5e2d7/W2w3pB7/m9IrLCW/9JKe95GL8DK4GW3uvLAZcAn6b3nnjmev/3euvY1Nv+54vI8yKyG3g8vW1fRJ4ELgPGePMYEzD/q0TkZ2/7GCuS9qgHQFWPAh/gkmegm4H3VPUE8Ddghqr+4r3md1V9NYN1eydonrcAb2f4jpD6PRknIjO9bWyOiFQPGK8icqeI/Az87A1L7zNtKCJLvHlNAtL7PPMOVbW/dP6ATbi9J4BquC/qaO95VWAXcB0uqV/tPa8IlAT2AzW9aSsDdbzHjwPvBiyjBm6PrbD3fDbQ03vcHfgmgxjnAC/hNsoGwE7gykheD3QCtuC+oAKcizuKKgKsBx4EigL/BxwIWJ83gT+AC73lzsLtOd4MxAFDgf8FvY+rgDOBcsB8YKg3rjzQASgBJAAfAlMCXjsb+A2oAxT2Ygt8jyYAD3mfQXHgUm94OWAPbg+4MG6vdg9QPmC+vwDn4/ZwZwPDw7xPzYETwHNAMdxe96GA92MU7ge7nLcO04CnAl6bGDS/uUAH7/GXXhzXBoxrF8F8GwE7gIu89/wW730uFvCeLwCqeK9fC9weZv26A98A/wQmecPuAF7xPss3M9gGaxCwDQfM8wTwL+/9jycT237ANAp8hjvaOQu3fV8TJo5muO9dvPf8NOAI0MB7fhOwGxiEOxqKi+T7D/wE1PLe582474gCNTJ4/Zu4783l3nYzmoDvozePmd7nE5/eZ4r7Hv4KDMB9BzoCx/G+R3n5z46IIjNFRA7gNsAdwGPe8JuA6ao6XVWTVXUmsAiXmACSgQtEJF5Vt6nq6mgHJiJn4q4D3a+qR1V1Ge4oqFuEs+gJPKOqC9VZr6q/AhcDpXA/zH+q6izcj0GXgNdOVtXF6vZEJwNHVfVtVU0CJuFOYwYao6qbVXU38GTKvFR1l6p+rKqHVfWANy749MqbqrpaVU+o6vGgccdxPwxVvPcg5Zra9cDPqvqO97oJwI9A64DXvqGq61T1CG5vugHpe0RVj6nqHOBz4EZv77wXMEBVd3vrMAzonM585gBXiDsKrge84D0vjtspmBfBfHsBr6jqD6qapO6a2THcZ5fiBVXd6r3n0yJYv8lAcxE5DbdTEdGefzq2quqL3vt/JBvzGa6qe1X1N+B/hFkPVZ0PbAfaeYNuBNZ53wtU9V1cYmyJ+wx2iMjgCJafclR0NW4b2pKJ2D9X1bmqegy3w9TU+96meMr7fI+Q/md6MS4BjVLV46r6EbAwE3HkWpaIItNWVRNwe7Z/BVJO31QHOnmH0HvFnTq7FKis7prMP4DbgW0i8rmI/DUGsVUBUn6kUvyKO1qLxJm4vfFQ892sqsnpzHd7wOMjIZ4HN+rYHDSvKgAiUkJEXhGRX0VkP+6IoIyIxIV5bbD7cEdzC8SdQrw1YB1+DZo2eB1+D3h8OETMgfZo2mttKetQEXc0tzhgO/jCGx7OHNz21Ah3lD0Tl3wvBtar6h8RzLc6MDBo+zvTiykr64f3Y/g58DBQwfthz470PrfMyMx6vM3JU2ndgDSNWlT1PVW9CneEdTvwbxFpmcHy38EdLXYn88k59T1Q1YO4I7IqocaT/mdaBdii3qGUJ3j7zpMsEWWCtxf8JjDSG7QZeEdVywT8lVTV4d70M1T1atxpuR+B17zXHcL9wKSolN5iMwhrK1BORBIChp1F5Htsm4Fzwsz3TEnbMCAz8w0lcC/wLG8ZAAOBmsBFqloadxoDXHJJEfZ9UHeev5eqVgH6AC+Ja+67FffFDpSddSjrXfMJXoc/cIm3TsB2cJq6i+HhYv8Wt87tgDmqusab3/W4JEUE890MPBm0/ZXwjvyy423cZ/JOJl4T7vMJHp7Rth+N7gDeBq4Ukaa4xP5+yMDcUcWHwArggvRm6J0l2Ig72/FJJuNJ3e7Ftbgtx8ltH9Kuc3qf6TagatD1sbMyGUuuZIko80YBV4tIA+BdoLWItBSROBEpLq6pbjUROUNE2ng/XMeAg0CSN49lwOUicpZ3CiS9VnjbgWoiUjTUSFXdjPtRe8pbfj3gNuC9CNdnPHCviFwozrnexdQfcD8a94lIEXGNMFoDEyOcbyh3eu9NOdy1p5RGBQm4H9y93rjHws0gFBHpJCcbN+zBfbGTgOnA+SLyT+9i+D+A2rhTjFk1RESKishlQCvgQ++o8TXgeRE53YupasBe9nagvPdZA6Cqh4HFwJ2cTDzf4hLpHG+ajOb7GnC7iFzkfXYlReT6oJ2SrJiDOwX1YiZesxN3KvovGUyX0ba/PYJ5pMtLGt/grh3OVNfICEhtQHS9iCSISCERuRZ37fGHCGZ9G/B/mvkWqNeJyKXed/gJ4AfvextKep/pd7hrbnd523N7IF/ckmGJKJNUdSduj+sRb2O6AfejuhO3NzMI974Wwu1VbsUdil+Bu/iLdy1pEm5PbDHp/zDOAlYDv4vIH2Gm6YK76LsVd47/MW8ZkazPh7hrMu/jLqpOAcqp6p9AG+Ba3J75S8DNqvpjJPMN433chfkN3l/KjXijcBdq/wC+x51+yoy/AT+IyEHchf3+qrpRVXfhksVAXCOS+4BW3mmvrPgdl+i24hL97QHvx/24xh3fe6cXv8Id8eBNMwHY4J1uSTktMwd3zn9BwPMETrZAy2i+i3DXFMZ4ca3HnTrKFu9a4dfedaVIX3MYtx3N99bx4jDTZbTtjwY6imsd90LW1gBwp+Oqc+pptP247+tvwF7gGaBvwHXFsFT1F+89z6z3cTtXu3GNe7qGmzC9z9T7Trb3nu/BnfrP7NFZriRpTzcaExsisgnXGuorv2MxJqeIuxE4UVUf9juW3MyOiIwxxvjKEpExJiIi0lVO3pQb+Bf12xLyEq+lZqj3JewpOJOWnZozxhjjKzsiMsYY46s8k4i8Q92wzTrF1dW6KidjChNHxFWIJfuVtU0eI/mkbH8KiVJ3HJn53pi8RYLqC4aSZxKRqpZS1Q2Q/77MkQj4oqacf94urjjo1bkkrsIBw1K6FBgUNG2iBBSFzeQ8K4sr7LpVQpTfF1cY9GdxxSB/FJGbg8a/KiI/iUiyiHTP2trmLIliv1SxWo7moe44TNbkxE5+nklEJlUZ7876+riyMJNz6Q/rbuB+8SpKR0Ey7v6iDmHGH8LdcHsarlDkaAmotA0sx93HtSRK8RhjokV9rLgK9ACmBTxfD3wQ8HwzJ6vmKq4ydG9ckcs/cdUKpunJKrn34m6U24e7aa54mOV2x1V/fh53U9sGXLn77pwsbHpLwPSn4W6M24mr7fQwUMgbF4cr+fOHN587SVtN+DTgP7jyHFtwN3HGBcSRbmXtgBhqBM43YPi9uLvRU+KpAnzsxboRuCtg2sdxhT3fxt28uhpoHDD+fi/GA7hqwykVvAsBg3E16XZ58yjnjfvNi+ug99eUk5Wcp+Furk2ZfyLQPCvzDJhHYSKrevwpMDDE8G+A7hm8Nr3PO2XdRuJuKtyIVzU7zLwa4pLfAdw2OZGTVcfL4m7o3OnN6zNcB4bgbg5NAo5678EYb/ho3Da6H3dD6GUBy2qCK7q739smngsYdzGucsNeXFJunt5ygtahOK6KyC7v9QuBM7xxswmqFB/uvQHOxt2sewB3Y+5YvErcnFqFO+z3Jp33Og54Fvdd3Aj0i3SeEcSelXjOwd2QvsuL6T3cjmTKeAXODXj+JgGVtHE3YG/D3UDdM3B6b9qXcF2MHMT9nlXC3Ry+B1dSrGHAvLL0u4Ar85SMq3xyELgvve0p4HOe481rJu7m3HfTfa8i+RGM1R+ulMde3I9SZdyXfkvAuD2c/AEI/hCGBs1rE5kreX8ClwhTuiz4DffFKAb83XsTS3nTvw1Mxd31XgPXUdht3rjbvQ89pXuD/5F245+CK6VfEjjdi7FP4MYfENdnwOAwMdcgdCL6ize8lvc+LgYexZWM/wsuObYM2OCO4uplxQFPAd9742rifuCqBCzvHO/x3biKB9W89+cVYEK4uDj5pW7gfb4pCSYwEWVqngHzzjAR4ao0bCNEVwFElojS+7y743aEennvYV/cD4WEmE+6ZfuJrPuL4C4RbvJeVxhXMeJ3vB0uXAmYbt7jUsDF3uOw3ZWEW07QMvvgdipKeOt8IVA6+LUZvTdefCO99+VSXMIMl4jCfm/SifN2YI23TZXFJbvMfBfTiz0r8ZzrvdfFcIVq5+IqZ2eYiHCd+f2OKz9UApcQgn8DI+qGhWz8LgT8tl4V8Dyj7ek7TnaXcjnutzT3JiIv6M24CsSdgVe9D/ivuCTxaagPjfCJ6KaA588A48Isszuue4CU53W9+Z8RMGwX7oc0DlcrrnbQF3O293gWAQkPl8QU90Nxhvfa+IDxXQI2kO5k/4iouDe8Ga4Pk9+Cxj+A6+ogZYP7KmBcbeBIwJdmB67vlSJB81iLd3TkPa+M+9IWDhVX4Hrh9rSe9h4HJqJMzTNgukgS0Vu403ihkkO6iSiCz7s7rjp2yrgSXjyVQszrcoKSFG4vMmT/Md72tifg+WzSSRDeNHuA+t7jucAQXNXswGnuxxXnDRw2A++oP6PlALd6cdcLMS71tem9N7jinCeAEgHj3yVEIiKD7006cc4iIDl423JmvovhYs9SPCHiawssDXieXiJ6Ha/fqYDvZ/Bv4GsB4/8FrA14XhfY6z3O8u+C93wTaRNR2O0p4HMuGTDufTJIRLmhhUpKOfxzvcd7cXXZmnKyGGSkgkvFVwk3Iad2WYCqhurGoAIn92xTBHYlUIVTuzdIUR23J7xNThbMLUT0SuMTEMdu3MZXRdL25BoHzAt4HvweFReRwqq6XkTuxm2UdURkBnCPqqZUsJ4sIoFdQiThvqAZeRTXPcPzQcOzM8+wRGQErpJyC/W+BZmU0ecNAe+hqh72PttQ3RKkW7ZfRErgTg9fg9uDB0gQkTh1fTqdQkQG4k7TVMH9MJXmZLcktwH/Bn4UkY3AEFX9jJPdlQT2w1QEd/QeiXdwR/wTRaQMLoE8pKf2CwXh35sKuO5KDgdMu5m0FdlTZPV7E/xdDO5eIaN5hou9XFbiEVeo9gVcr7MJ3mv2ZLAOgesSWNcu1LIi7YalOln/XTgRYrnpbU9VCN1dSqjPOVVuSUStcecVh+ESUVdcIhoT5jVZ+YHJqj842fHaGm9YYFcC2zi1e4MUm3F7UhXCfKDR0A53JPMTrn+Vjap6XlZmpKrvA+97DQxeAZ7G9eeyGbhVQ/RNIwHdHoeZ548i8gmu0GSgLM8zHHFdoV8LXKGq+7MyDzL+vDMjtWx/QDI6i5P9PwV2f/G7uIruSznZ/UWa7Vxcxe/7gSuB1aqaLCJ7UqZX1Z+BLuK67mgPfCQi5TnZXUmvMHGm+33yEs4QXOXxGriq5j/hrplEahuuu5ISAcko3I9TVr8323Cn5VIEzj8738WsvvYp3HtbT1V3iUhb0v6mHebULjESvcfprUtmbSYbvwucun2E3Z68725ZESkZkIzOCjGPNHJDq7k5QAvcYW8iLktfgzsPvjTMa7JdKj5S3p7pB8CT4krHVwfuwe0V4o27S1z3BmVxF+BTXrsNV236WREpLa7s/DkickV24xLXzUQ/XFXfB9R1GbAA2C8i94tIvLiuKS4Qkb9FML+aIvJ/IlIMd774CCe7rRjnrX91b9qKInKDNy6S8v9DcKdaywQMy/Q8xfVeWsx7Wsx7njLuAVzHZVerq7odvH5FvekFKCKuy4xTtv8IPu/MyKhsf0bdXwRv5wne/HYChUXkUdwRUco63iQiFb1tIWXvN4l0uisJs5w0RKSFiNQV11HhflyiDnnEFo66rhkWAY97n0VT0vaUGzhtVr83HwD9xXWVUQaXtLM7z+y8NgF3gX+viFTFVeYPtAz4p/eZXEPaXok/AHqISC3vyPnRjOJMR5Z/FzzB20fY7Sngcx7ifc6XEuZzDuR7IlLVdbgPa573fD/uQtr8cKcncHtitcWVm5+SA2H+C9c8eAPuGsP7uHO44PoPmYFrObKEU8uy34w71bMGd1j+Ee56yCnE3RwYfOQQbK+IHML16nkd0ElVX4fUH9HWuGsNG3F79+NxLX4yUgwY7r3md9wF2ZRYRuNaoX0prsv073HnndEIyv+r6kbc6Z3ATuWyMs+UljvgGogEdj09DLfn9bOcvNcq8L380pv+Ety1yCOc7IAvWHqfd8Q047L9GXV/EdwlwgxcK6l1uNMdR0l7yuYaYLW47jBGA53VdZ2eXncloZYTrBJuu92Pu7Y3h6wl5pQzHbtwF9Mn4Y40Qon4exPgNdznvAK3Ezsdl7hTfkeyMs/sxDMEd/17H67X2+Dfhv6472vKWaDU3zJV/S/utN7/cK2Jv/NGhXu/wsrm7wK4I7uHve/ivRFsT//EfZd343auMuzR1mrNGWN8ISKTgB9VNfhIMFrzvxbXYClLp3pzExGpBawCisXwNL9vfD8iMsYUDCLyN++UViHvVNQNBBwFRGH+8SJynXcatCpub3xytOaf00SknXd6qyzueu20/JiEwBKRMSbnVMI19z6IO+3UV1XDXQcOSUTGSeguF8bhrv8NwZ06W4o7jZidayvZjSe7+uBOff2CO73YNwrzzJXs1Jwxxhhf2RGRMcYYX+WG+4iirkKFClqjRg2/wzDGmDxl8eLFf6hqxZxebr5MRDVq1GDRokUZT2iMMSaViPya8VTRZ6fmjDHG+MoSkTHGGF9ZIjLGGOOrfHmNKJTjx4+TmJjI0aNH/Q7F+KR48eJUq1aNIkWK+B2KMSZAgUlEiYmJJCQkUKNGDeRkKXdTQKgqu3btIjExkbPPPtvvcIwxAXw9NSciZ4rI/0RkrYisFpH+IaZpLiL7RGSZ95elO6WPHj1K+fLlLQkVUCJC+fLl7YjYmFzI7yOiE8BAVV0iIgnAYhGZqaprgqabp6qtsrswS0IFm33+xuROvh4Rqeo2VV3iPT6Aqw1VNf1XGWOMCWXbtm1+h5AluabVnLieHxsCP4QY3VRElnv99dQJ8/reIrJIRBbt3LkzhpHmLY8//jgjR45Md5o333yTrVu35lBExphoO3z4MPfeey9nn302y5Yt8zucTMsViUhESgEfA3eH6OJ5CVBdVesDLxKmbLyqvqqqjVW1ccWKOV6hIk+zRGRM3jV79mzq1avHs88+S/fu3fNkYxzfE5GIFMElofdUNbgHQ1R1v6oe9B5Px3XzXCGHw8y2Rx55hNGjR6c+f+ihh3jhhVCdYaa1b98+atasyU8//QRAly5deO21106ZrkaNGtx///00adKEJk2asH79+lOmWbZsGRdffDH16tWjXbt27Nmzh48++ohFixbRtWtXGjRowJEjR055nTEmdxo3bhwtWrQAYNasWYwbN47TTou049Xcw9fGCuKuHv8HWKuqz4WZphKwXVVVRJrgkueu7C67efPmpwy78cYbueOOOzh8+DDXXXfdKeO7d+9O9+7d+eOPP+jYsWOacbNnz053ebfddhvt27enf//+JCcnM3HiRBYsWMCBAwe47LLLQr7m/fffp3bt2owZM4bu3bvTv39/9uzZQ69evUJOX7p0aRYsWMDbb7/N3XffzWeffZZm/M0338yLL77IFVdcwaOPPsqQIUMYNWoUY8aMYeTIkTRu3DjddTDG5A5Hjx6lePHitGrVil9//ZVHHnmEEiVK+B1Wlvndaq4Z0A1YKSIpJzYfBM4CUNVxQEegr4icAI4AnTUPdqJUo0YNypcvz9KlS9m+fTsNGzakfPnyABme07366qv58MMPufPOO1m+fHnY6bp06ZL6f8CAAWnG7du3j71793LFFVcAcMstt9CpU6fsrJIxJoft3LmT/v37s2PHDmbOnEm1atV46qmn/A4r23xNRKr6Da5XxfSmGQOMifay0zuCKVGiRLrjK1SokOERUCg9e/bkzTff5Pfff+fWW28FiOiIKDk5mbVr1xIfH8/u3bupVq1ayOkDmydbU2Vj8g9VZcKECdx1113s37+fhx9+mKSkJAoX9vtYIjp8v0ZUkLRr144vvviChQsX0rJlSwASEhJYtmxZyL/atWsD8Pzzz1OrVi0mTJjArbfeyvHjx0POf9KkSan/mzZtmmbcaaedRtmyZZk3bx4A77zzTurRUUJCAgcOHIjJOhtjsmfHjh20adOGrl27cs4557BkyRIeffTRfJOEwP9TcwVK0aJFadGiBWXKlCEuLi6i16xbt47x48ezYMECEhISuPzyyxk6dChDhgw5Zdpjx45x0UUXkZyczIQJE04Z/9Zbb3H77bdz+PBh/vKXv/DGG28A7trX7bffTnx8PN999x3x8fHZW1FjTNTEx8ezfv16nnvuOe66666IfzvyEsmDl1sy1LhxYw3uGG/t2rXUqlXLp4ic5ORkGjVqxIcffsh5550X1XmndAZYoUKea1CYo3LDdmBMRtavX8/TTz/NmDFjKFasGCdOnMiRIyARWayqOd5qyU7N5ZA1a9Zw7rnncuWVV0Y9CRlj8ocTJ04wcuRI6taty4cffsiqVasA8tVpuFDy99rlIrVr12bDhg0xm/+mTZtiNm9jTOytWLGC2267jUWLFnHDDTfw0ksvUaVKFb/DyhGWiIwxxmeqSp8+ffj111+ZOHEiN954Y4Fq+WqJyBhjfPLDDz9w3nnnUa5cOd555x3Kli2ben9hQWLXiIwxJocdOnSIe+65h6ZNm/LEE08AcO655xbIJAR2RGSMMTnq66+/plevXmzcuJE77rgj5K0YBY0dERljTA55+eWXueqqqyhcuDBz585l7NixlC5d2u+wfGeJKAeJCN26dUt9fuLECSpWrEirVuE7n509ezbffvttppe1d+9eXnrppTTzSW854LqDSKlXl+KPP/6gYsWKHDt2jM8++4yGDRtSv359ateuzSuvvBJyHiLC119/nTps8uTJiAgfffRRptcjq0qVKpVjyzImIylV7du0acNDDz3E8uXLw5b2KogsEYUxZekWmg2fxdmDP6fZ8FlMWbol2/MsWbIkq1atSt0oZ86cSdWq6XdIm14iOnHiRNjXBSeiSLRv356ZM2dy+PDh1GEfffQRbdq0oVChQvTu3Ztp06axfPlyli5dGrKCOUDdunXTVHaYOHEi9evXz1QsoaS3vsbkRjt27KBz585cf/31qCpVq1Zl6NChVr0kiCWiEKYs3cIDn6xky94jKLBl7xEe+GRlVJLRtddey+effw7AhAkTTjkCCbRp0ybGjRvH888/T4MGDZg3bx7du3fnnnvuoUWLFtx///2n9MB6wQUXsGnTJgYPHswvv/xCgwYNGDRoEAAHDx6kY8eO/PWvf6Vr164EV9UoXbo0l19+OdOmTUsdNnHiRLp06cKBAwc4ceJE6sXUYsWKUbNmzZBxX3bZZSxYsIDjx49z8OBB1q9fT4MGDdJ9X8L1pxS8vr/88gvXXHMNF154IZdddhk//vgjABs3bqRp06b87W9/45FHHkl3WcbEmqry7rvvUqtWLSZPnsz//d//kZSU5HdYuZYlohBGzPiJI8fTbjRHjicxYsZP2Z53586dmThxIkePHmXFihVcdNFFYaetUaMGt99+OwMGDGDZsmWph/Lr1q3jq6++4tlnnw372uHDh3POOeewbNkyRowYAcDSpUsZNWoUa9asYcOGDcyfP/+U13Xp0oWJEycCsHXrVtatW0eLFi0oV64cbdq0oXr16nTp0oX33nuP5OTkkMsWEa666ipmzJjB1KlTadOmTUTvTUp/Sv369ePuu+9OHR64vr179+bFF19k8eLFjBw5kjvuuAOA/v3707dvXxYuXEilSpUiWp4xsbB9+3auv/56unXrRs2aNVm2bBkPP/xwvq+OkB2WiELYujd0L6XhhmdGvXr12LRpExMmTAjZ+V4kOnXqlKXCh02aNKFatWoUKlSIBg0ahKzG0KpVK7755hv279/PBx98QMeOHVOXNX78eL7++muaNGnCyJEjU7uyCCUl4aYcUUUisD+l7777LnV4yjMSw10AACAASURBVPoePHiQb7/9lk6dOtGgQQP69OnDtm3bAJg/f37q6wOvwxmT00qUKMGmTZsYPXo08+bNs9qGEbAUHUKVMvFsCZF0qpSJznndNm3acO+99zJ79mx27cp8Z7MlS5ZMfVy4cOE0RyZHjx4N+7pixYqlPo6Liwt5zSU+Pp5rrrmGyZMnM3HiRJ5//vk04+vWrUvdunXp1q0bZ599Nm+++WbIZTVp0oRVq1YRHx/P+eefH9F6hetPKWV9k5OTKVOmTNiOBAvSnegmd1m3bh3Dhw/n5ZdfplSpUqxYscKOgDLBjohCGNSyJvFF0h5xxBeJY1DL0NdEMuvWW2/l0UcfpW7duhlOm1FfQTVq1GDJkiUALFmyhI0bN0b0uvR06dKF5557ju3bt3PxxRcD7vpSYGeAy5Yto3r16unO56mnnmLYsGERLze9/pTAnbo7++yz+fDDDwF3Hj6lx9pmzZqlnlJ87733Il6mMdlx4sQJnn76aerVq8cnn3zCypUrgfxfpDTaLBGF0LZhVZ5qX5eqZeIRoGqZeJ5qX5e2DdNv4RapatWq0b9//4imbd26NZMnT05trBCsQ4cO7N69mwYNGvDyyy+nHn2UL1+eZs2accEFF6Q2VojU3//+d7Zu3co//vGP1KMMVeWZZ56hZs2aNGjQgMceeyzs0VCKa6+9lhYtWkS83JT+lEaPHn3KkViK9957j//85z/Ur1+fOnXqMHXqVABGjx7N2LFj+dvf/sa+ffsiXqYxWbV8+XIuuugiBg8ezHXXXcfatWtp3LixHZlngfVHZHKFnOpPybYDEw2qyiWXXMKGDRsYO3YsHTp0yBcJyK/+iOz40RhjIvTdd99x/vnnF/gipdFmiSiXeOONNxg9enSaYc2aNWPs2LE+RRQb7dq1S72OleLpp5+2/pRMrnbw4EEefPBBxowZQ//+/Xn22Wc599xz/Q4r3yhQiUhVc+3hc48ePejRo4ffYcTc5MmTfVt2fjwNbWLvyy+/pHfv3vz666/069ePf//73xQqZJfXo6nAvJvFixdn165d9mNUQKkqu3btonjx4n6HYvKQsWPH0rJlS4oXL868efN48cUXSUhI8DusfKfAHBFVq1aNxMREdu7c6XcoxifFixenWrVqfodh8oDDhw9TokQJ2rZty/bt23nwwQdtJyaGfG01JyJnAm8DlYBk4FVVHR00jQCjgeuAw0B3VV2S3nxDtZozxpiM/P777/Tr149du3Yxa9asXHsqP1b8ajXn96m5E8BAVa0FXAzcKSK1g6a5FjjP++sNvJyzIRpj8jtV5a233qJ27dp89tlntGzZMmwtRRN9vp6aU9VtwDbv8QERWQtUBdYETHYD8La6Q7fvRaSMiFT2XmuMMdmyfft2brnlFmbMmEGzZs34z3/+E7ayvIkNv4+IUolIDaAh8EPQqKrA5oDnid6w4Nf3FpFFIrLIrgMZYyJVsmRJtmzZwpgxY5g7d64lIR/kikQkIqWAj4G7VXV/8OgQLznlwpaqvqqqjVW1ccWKFWMRpjEmn/jxxx/p0aMHR48epVSpUixbtow777zTmmX7xPd3XUSK4JLQe6r6SYhJEoEzA55XA7bmRGzGmPzl+PHjPPXUUzRo0ICpU6eyZo27CpCVblVM9PiaiLwWcf8B1qrqc2Em+xS4WZyLgX12fcgYk1lLly6lSZMmPPjgg7Ru3Zq1a9fSqFEjv8My+H8fUTOgG7BSRFI6mXkQOAtAVccB03FNt9fjmm/n//IDxpioUlXuvPNOtm3bxscff0z79u39DskE8LvV3DeEvgYUOI0Cd+ZMRMaY/OSbb76hVq1alC9fPrVIably5fwOywTx/RqRMcZE24EDB+jXrx+XXXYZQ4cOBeCcc86xJJRL+X1qzhhjouqLL76gT58+bN68mf79+/PEE0/4HZLJgCUiY0y+MWbMGP71r39Rq1Yt5s+fH7LLeZP7WCIyxuR5hw4domTJkrRv355du3YxePBgihUr5ndYJkJ2jcgYk2dt27aNDh06cP3115OcnEyVKlV47LHHLAnlMZaIjDF5jqryxhtvULt2baZPn851111nfY3lYXZqzhiTp2zbto2bb76Zr776issuu4zx48dz/vnn+x2WyQY7IjLG5CkJCQn8/vvvvPTSS8yePduSUD5gicgYk+utXbuWbt26pSlS2rdvXytSmk/Yp2iMybWOHz/O0KFDadCgAdOnT2ft2rWAFSnNbywRGWNypcWLF9O4cWMeeeQR2rVrx9q1a2nYsKHfYZkYsMYKxphcR1X517/+xc6dO5kyZQo33HCD3yGZGLJEZIzJNebOnUudOnUoX7487733HmXLlqVMmTJ+h2VizE7NGWN8t3//fvr27csVV1zBk08+CcDZZ59tSaiAsCMiY4yvpk+fTp8+fdiyZQsDBgywIqUFkB0RGWN8M2bMGK6//npKly7Nt99+y3PPPUfJkiX9DsvkMDsiMsbkKFXl0KFDlCpVig4dOrBnzx7uu+8+qw9XgNkRkTEmx2zZsoW2bdvSqlUrkpOTqVy5Mo888ogloQLOEpExJuZUlddee43atWvz5Zdf0rp1aytSalLZqTljTExt27aNm266iVmzZtG8eXNee+01zj33XL/DMrmIJSJjTEwlJCSwa9cuXnnlFXr27Gn14cwpbIswxkTdqlWr6Nq1a2qR0iVLltC7d29LQiYk2yqMMVHz559/MmTIEBo1asSXX36ZWqTUEpBJj20dxpioWLhwIRdeeCGPP/44nTp1Ys2aNVak1ETE90QkIq+LyA4RWRVmfHMR2Sciy7y/R3M6RmNM+lSV/v37s2fPHj799FPee+89Klas6HdYJo/IDY0V3gTGAG+nM808VW2VM+EYYyI1e/ZsLrjgAipUqMD7779P2bJlOe200/wOy+QxER0Ricg5IlLMe9xcRO4SkahUI1TVucDuaMzLGJMz9u3bR58+fWjRogXDhg0DoEaNGpaETJZEemruYyBJRM4F/gOcDbwfs6hO1VRElovIf0WkTqgJRKS3iCwSkUU7d+7MwdCMKVimTZtGnTp1GD9+PPfeey9Dhw71OySTx0WaiJJV9QTQDhilqgOAyrELK40lQHVVrQ+8CEwJNZGqvqqqjVW1sZ2bNiY2XnjhBdq0aUO5cuX44YcfGDFiBCVKlPA7LJPHRXqN6LiIdAFuAVp7w4rEJqS0VHV/wOPpIvKSiFRQ1T9yYvnGFHSqysGDB0lISKBTp04cPHiQe++9l6JFi/odmsknIj0i6gE0BZ5U1Y0icjbwbuzCOklEKomIeI+b4GLelRPLNqagS0xMpE2bNmmKlD744IOWhExURXREpKprROR+4Czv+UZgeDQCEJEJQHOggogkAo/hHW2p6jigI9BXRE4AR4DOatUSjYmp5ORkXnvtNQYNGsSJEycYNmyYFSk1MRNRIhKR1sBIoChwtog0AP6tqm2yG4Cqdslg/Bhc825jTA7YunUr//znP5kzZw5XXnklr776Kn/5y1/8DsvkY5GemnscaALsBVDVZbiWc8aYfKZ06dLs27eP8ePHM3PmTEtCJuYiTUQnVHVf0DA7Tjcmn1ixYgWdO3fmyJEjlCpVisWLF3PbbbfhXZ41JqYiTUSrROSfQJyInCciLwLfxjAuY0wOOHbsGI8++igXXnghs2bN4qeffgKsSKnJWZFubf8C6gDHgAnAfuDuWAVljIm977//nkaNGvHEE0/QpUsX1q5dS4MGDfwOyxRAkbaaOww85P0ZY/I4VWXgwIEcOHCA6dOnc+211/odkinAIm019z9CXBNS1f+LekTGmJj5+uuvqVevHhUrVkwtUlq6dGm/wzIFXKSn5u4FBnl/jwDLgEWxCsoYE1179+7ltttu46qrrmL4cHcLYPXq1S0JmVwh0lNzi4MGzReROTGIxxgTZVOmTOGOO+5gx44d3H///Tz22GN+h2RMGpGemisX8LQQcCFQKSYRGWOiZtSoUQwYMIB69eoxbdo0LrzwQr9DMuYUkRY9XYy7RiTACWAjcFusgjLGZJ2qsn//fk477TQ6d+7MsWPHuOeeeyhSJEfqFBuTaZIf60c1btxYFy2yS1im4Pntt9/o06cPhw4dYvbs2XY/kMkUEVmsqo1zernpHhGJSPv0xqvqJ9ENxxiTFcnJybz88ssMHjwYVeWpp57yOyRjIpbRqbnW6YxTwBKRMT7bsmULXbp0Yd68eVx99dW8+uqr1KhRw++wjIlYuolIVXvkVCDGmKwpU6YMhw8f5vXXX6d79+5WH87kOZE2VkBErseV+SmeMkxV/x2LoIwx6Vu2bBnDhg3jrbfeomTJkixcuNASkMmzIrqSKSLjgH/gas4J0AmoHsO4jDEhHD16lIceeojGjRszd+5c1q1bB2BJyORpkTapuURVbwb2qOoQXLfhZ8YuLGNMsG+//ZaGDRsybNgwbrrpJtasWUP9+vX9DsuYbIv01NwR7/9hEakC7MI6xjMmx6gqgwYN4vDhw3zxxRe0bNnS75CMiZpIE9FnIlIGGAEswbWYey1mURljAJg5cyb169fn9NNPZ8KECZQtW5aEhAS/wzImqiI6NaeqT6jqXlX9GHdt6K+q+mhsQzOm4Nq9ezc9evTg73//O08//TQAZ511liUhky9F2lhhuYg8KCLnqOqxEN2GG2Oi5OOPP6Z27dq88847PPDAAzz55JN+h2RMTEXaWKENrsbcByKyUETuFZGzYhiXMQXS888/T8eOHalSpQqLFi1i2LBhFC9ePOMXGpOHRdoNxK/AM8AzInIerk+ip4G4GMZmsmjK0i2MmPETW/ceoUqZeAa1rEnbhlX9DsuEEViktEuXLiQlJXH33XdTuHDEt/kZk6dl5obWGsCNuPuJkoD7YhOSyY4pS7fwwCcrOXI8CYAte4/wwCcrASwZ5UK//vprapHSOXPmUKlSJe69916/wzImR0V6jegHXF25QkAnVW2iqs9GIwAReV1EdojIqjDjRUReEJH1IrJCRBpFY7n51YgZP6UmoRRHjicxYsZPPkVkQklOTubFF1+kTp06zJ8/n86dO/sdkjG+ifSI6BZV/TFGMbwJjAHeDjP+WuA87+8i4GXvvwlhy94jmRpucl5iYiKdO3dm/vz5tGzZkldeeYXq1a1QiSm4Im2+HaskhKrOBXanM8kNwNvqfA+UEZHKsYrHmFgrW7Ysf/75J2+99Rb//e9/LQmZAi8vXA2tCmwOeJ7oDdsWOJGI9AZ6g7vfwphQ/GrIsWTJEoYNG8Y777xDyZIl+eGHH8LWh7PGJqagyQvdN4b6tp7SrayqvqqqjVW1ccWKFXMgLJPXTFm6hUEfLWfL3iMo7nTloI+WM2Xplpgt88iRIzzwwAM0adKE+fPn8/PPPwPhi5ROWbqFQR8GxfhhbGM0xm95oYfWRNIWWK0GbM2B5Zp8Zsi01RxPSrsPczxJGTJtdUyOOObNm0fPnj1Zt24dt956KyNHjqRs2bLpvubxT1dzPDkoxmTl8U9jE6MxuUGkPbSeDlwCzPKetwBmkzM9tH4K9BORibhGCvtUdVsGrzHmFHsOH8/U8OxQVR544AH+/PNPZs6cyVVXXRXR6/YeCR1LuOHG5AcR9dAqIp8BtVMSgNdYYGw0AhCRCUBzoIKIJAKPAUW85Y8DpgPXAeuBw4D1GmtyrS+++IJGjRqlFiktV64cJUuW9DssY3K1SBsr1Ag6CtkOnB+NAFS1SwbjFbgzGssyJlZ27drFgAEDeOeddxg4cCAjR47kzDOtyy5jIhFpIpotIjOACbiGAp2B/8UsKmPyCFXlo48+ol+/fuzevZuHH36Yhx9+2O+wjMlTIq01109E2gGXe4NeVdXJsQvLmLzh+eefZ+DAgTRq1Igvv/wyz/aYGssm4w9PWcmEHzaTpEqcCF0uOpOhbetGZd4mf8jMfURLgAOq+pWIlBCRBFU9EKvAjMmtVJW9e/dStmxZunbtCsBdd92VZ4uUxrI+4cNTVvLu97+lPk9STX1uycikiLTWXC/gI+AVb1BVYEqsgjImt9qwYQNXX301rVq1IikpiTPOOIN77rknzyYhiG19wgk/bM7UcFMwRXpD651AM2A/gKr+jGvSbUyBkJSUxKhRo6hbty4LFiygW7duYW9KzWtiWZ8wSU+59zzd4aZginQ37piq/pnyxRORwoSobmBMfpSYmEinTp34/vvvue666xg3bly+ahEXJxIyMcRFIdEWEkgO8UtRKH/kcBMlkSaiOSLyIBAvIlcDdwDTYheWMblHuXLlUFXeffdd/vnPf+abI6EUsTxqKVa4EEeOJ4ccntNyooaf1QnMmki3hvuBncBKoA/uJlNro2ryrUWLFtGuXTsOHz5MiRIl+O677+jatWu+S0IAVcvEZ2p4ZhwNkYTSGx4rKQ0yAmv4PfDJyqjW8MuJZeRXGSYiESkErFTV11S1k6p29B7bqTmT7xw5coT77ruPiy66iAULFvDLL78A4YuU5gc1yodOOOGGZ0aVMMks3PBYyYkOI61TyqzLMBGpajKwXESsbwWTr82ZM4d69eoxYsQIbrvtNtasWUPduvm/ifH8X0J3BxZueGa0+GvoSvjhhsfK1jANL8INz63LyK8iPTVXGVgtIl+LyKcpf7EMzJicpKo89NBDJCcn8/XXX/Pqq69y2mmn+R1Wnvfx4sRMDY+VnDgyyy1Hf3lRpI0VhsQ0CmN8cuSXhRStdC4iwsSJEylbtqwVKY2iUA0V0hseKzXKx4dsjh6N048pBrWsmebGYID4InEMalkzasvIryIt8TNHRCoBTXDNtheq6u8xjcyYGEo6vI89X7/GoTWzKf23dsBNVKtWze+wTDqyUyro+w17MjU8K1Jax1mrucyLKBGJSE/gUVx/RAK8KCL/VtXXYxmcMdGmqhxeO5fdX71C8rHDnNasC6c1vdHvsEwGslsqKKdurG3bsKolniyI9NTcIKChqu4CEJHywLeAJSKTp+xfMJm9s1+naOXzKX/tXRStWMPvkEwE0isVFEkiEoFQOScfN4bMUyJNRIlAYIHTA4AVizJ5gqqyZ487BVPqghZIXBwJjVohheJ8jsxEKrtHNPGFC3E4xHWpeB9urDWnijQRbQF+EJGpuGtENwALROQeAFV9LkbxGZMtv/zyC7179+bIkSPopYOJK1mW0o1v8Dssk0nZLRWUWxpNmNAi3R34BVdtO2VTmApsAxK8P2NylaSkJJ599lnq1q3LokWL6NGjB4jt/eZV4UoCRVoqyJpW526RtppLt/m2iLyoqv+KTkjGZM/mzZvp0KEDCxcupHXr1rz88stUrVqVJwd/7ndoJouyWyrImlbnbtHaRWwWpfkYk23ly5encOHCTJgwgalTp1K1qrViyutKFA19PS/c8GBtG1alw4VVUyuKx4nQ4UJr4ZZb2LkKky8sWLCAG264IbVI6fz58+ncuXO+rhGXF5QtUSRTw8M5/GdSpoYHm7J0Cx8v3pLauCFJlY8Xb7GCpLmEJSKTpx0+fJiBAwfStGlTFi9ezIYNG4D8XaQ0L3msdZ1TGhQUEjc8M8K1jYv0LiArSJq7RSsR2bfe5Lj//e9/1K1bl+eee47evXuzZs0aLrjgAr/DMkHigjJR8POcYAVJc7doJaLRUZqPMRFRVR599FEKFSrE7NmzefnllyldurTfYZkgI2b8xPGktMctx5M0x49ErNVc7pZuq7mMKmyrahvv/5tZDUBErsElsjhgvKoODxrfHNdcfKM36BNV/XdWl2fytmnTptGkSRPOOOMMJk2aRNmyZYmPtx+T3CpUodH0hodTpBCEaiBXJMJdaWs1l7tl1Hy7Ka6CwgTgB6J8Ck5E4oCxwNW46g0LReRTVV0TNOk8VW0VzWWbvGXHjh3cddddTJo0iUGDBvHMM89QpUoVv8MyGYgTCVn9IC6T1/DCtdKO9H5UK0iau2WUiCrhkkQX4J/A58AEVV0dpeU3Adar6gYAEZmIq9oQnIhMAaWqvP/++/Tv358DBw7wxBNPcN999/kdlolQThUbjYQVJM290j2wVdUkVf1CVW8BLgbWA7NFJFo3r1Ylbc26RG9YsKYislxE/isiIZvbiEhvEVkkIot27twZpfCM30aOHMlNN93Eeeedx9KlS3n44YcpWrSo32GZCIU77rHWTSZQhpUVRKQYcD3uqKgG8ALwSZSWH2p7DN5VWgJUV9WDInIdrtTQeae8SPVV4FWAxo0b5/zuloma5ORk9uzZQ/ny5bnllluIj4+nb9++xMVZkdK8JrvNrqNpytItdmoul8qoscJbwAXAf4EhqroqystPBM4MeF4N2Bo4garuD3g8XUReEpEKqvpHlGMxucDPP/9Mr169OHbsGN988w2nn346/fr18zssk8dNWbqFQR8tT23Bt2XvEQZ9tBzAklEukFGbk27A+UB/4FsR2e/9HRCR/Rm8NhILgfNE5GwRKQp0BtK01BORSuLdnSgiTbyYd0Vh2SYXOXHiBCNGjKBevXosW7aMnj17UqiQ3W9tomPItNUhm5EPmZb+5e4pS7fQbPgszh78Oc2Gz7JKDDGS7hGRqsb0l0BVT4hIP2AGrvn266q6WkRu98aPAzoCfUXkBHAE6Kzqw5VOEzO//fYbHTp0YNGiRbRt25axY8daizgTVXsOH8/UcHBJKLDJ95a9R3jgk5WAHUVFW6T9EcWMqk4HpgcNGxfweAwwJqfjMjmnYsWKFC9enA8++ICOHTtaeR6TK6RXFsgSUXTZuQ/ji++++45WrVpx6NAh4uPjmTt3Lp06dbIkZHINKwuUcywRmRx16NAhBgwYQLNmzVixYgUbN7qCGZaATHriw5RQCDc8WFaqgFtZoJxjicjkmK+++ooLLriAUaNG0bdvX1avXm1FSk1EihcJ3XQ/3PBg19ernKnhAC3+WjFTw8EaN2SVJSKTI1SVIUOGUKRIEebOncvYsWNJSLBe5k1kstLYIND/fgx9k3u44QCfLd+WqeEpjRu27D2CcrJxgyWjjFkiMjE1ZcoUfv/9d0SESZMmsXz5ci677DK/wzIFTFau9+w9EjrJhRtufR5lnSUiExPbt2/nxhtvpF27djz33HMAVKlSxSplG1+cFh/6WlC44VlhjRuyzhKRiSpV5e2336ZWrVpMnTqVoUOH8uSTT/odlingDv95IlPDIfMNHKxxQ9ZZIjJRNWLECG655RZq1arF8uXLeeihhyhSJHp7ncZkxZ9Joe+BDzccMt/N+aCWNSkS9IIihcT6PIqA7ze0mrwvOTmZ3bt3U6FCBXr06EFCQgJ9+vSxEj0mauKLFOJIiM6HIm2+nVVxhYTkgGSVYTfnwaPtroSI2C+FyZZ169bRvHlzWrduTVJSEhUrVqRv376WhExUHQ3TA1644cHC3aaW3u1rme3mPLd0i54X2a+FyZLjx48zfPhw6tWrx8qVK+0IyMRU8TBHPuGGB7vkL+UyNRwy3/jAGitknZ2aM5n266+/0q5dO5YuXUr79u0ZO3YslSpV8jssk48dOxH6yCfc8GBrth3I1HBwjQy2hEgi6TVKyMz05iTbhTWZdvrpp1OqVCk+/PBDPv74Y0tCJuaSw7QpCDc8WFZuiB3UsibxQZUb4ovEhW18kNnpzUmWiExE5s+fz/XXX59apHTOnDl07NjR77BMAREX5mJOuOHR0LZhVZ5qX5eqZeIRoGqZeJ5qXzds5e3MTm9OslNzJl0HDhzgwQcfZOzYsZx55pls2rSJOnXqWJFSE5E4EZJCdB+W2QTS5aIzeff730IOj6W2DataIskBdkRkwpoxYwYXXHABY8eOpV+/fqxevZo6dULfQ2FMKH+pWCJTw8MZ2rYuN118VmoCixPhpovPYmjbuhG9vmTR0MVRww3PCqs1l3V2RGRCUlWGDRtGfHw88+bNo1mzZn6HZPKg9TsPZWp4eoa2rRtx4glWJK4QkBRmeHRYR3pZZ4nIpPHJJ59wySWXUKlSJSZOnEjZsmUpXry432GZPCrEWbl0h8fKvjCFSsMNzwprvp11dmrOALBt2zY6dOhAhw4deP755wGoXLmyJaECoEyYwp/hhudFOVEHzmrNZZ0logJOVXnjjTeoXbs2n3/+OcOHD7cipQXM423qhKyR9nib/HM9cFDLmhSJC1rHuOjWgbPm21lnp+YKuGeeeYbBgwdz6aWXMn78eGrWtC9NQZNy/WLEjJ/YuvcIVcrEM6hlzfx3XSP4dGCUTw8WmPcxBiwRFUDJycns2rWLihUrcuutt1KmTBl69eplJXoKsPzeTHnEjJ84HnT36/FkjXpDgvz+PsaK/fIUMGvXruWyyy5LU6TU6sSZWMlsnz6xYg0Jcjf79SkgNOkEw4YNo0GDBvz444/ceeedlnxMzD3Wuk7IazPh+vSJFWtIkLv5/kskIteIyE8isl5EBocYLyLygjd+hYg08iPOvOzEvh1se3sADz30EDfccANr1qyhW7duVh3BxFzbhlUZ0bF+mrI3IzrWz/HTV9aQIHfz9RqRiMQBY4GrgURgoYh8qqprAia7FjjP+7sIeNn7byIUV7IMhYqXYvLkybRt29bvcEw6brr4rJClbG66+CwfoomO3HDdxBoS5G5+N1ZoAqxX1Q0AIjIRuAEITEQ3AG+rqgLfi0gZEamsqttyPtzcT3CNgY5uXsW+7z6gYtsHKVS0OJW7PEXbttf7HZ6vShaN49Cfp95dH80yL9mVUjlgwg+bSVIlToQuF52Z5YoC5qTckBBNaH4noqrA5oDniZx6tBNqmqpAmkQkIr2B3gBnnZV39x6za1irc+l910AOLv2cwqedwYn9Oyha4Sye/0cDv0Pz3ZPt6jLww+UkJaft+vnJdrnrRz47pWyMyYv8TkShLlIEt+6PZBpU9VXgVYDGjRvncAGR3OG///0v9/fpw6HERCo360CRJl2odnpZOwXhXddDfQAADEdJREFUsdMzxuROfieiRCCwjns1YGsWpinwVJXhw4eTkJDAt99+y8UXX+x3SLmSnZ4xJvfxu9XcQuA8ETlbRIoCnYFPg6b5FLjZaz13MbDPrg85qspHH33Etm3bEBEmTZrEkiVLLAkZY/IUXxORqp4A+gEzgLXAB6q6WkRuF5HbvcmmAxuA9cBrwB2+BJvLbN26lfbt29OpUydGjRoFQKVKlShWrJjPkRljTOb4fWoOVZ2OSzaBw8YFPFbgzpyOK7dSVV5//XUGDhzIsWPHeOaZZxgwYIDfYRljTJb5fWrOZNLTTz9Nz549qV+/PitWrGDQoEEULuz7/oQxxmSZ/YLlAUlJSezatYvTTz+dnj17UqFCBW699VYr0WOMyRfslyyXW7NmDZdeemlqkdIKFSrQs2dPS0LGmHzDfs1yqT///JMnnniChg0b8vPPP3PXXXdZ8jHG5Et2ai4X2rRpE23atGHlypV07tyZF154gYoVK/odljHGxIQlolyoUqVKVKxYkalTp9KmTRu/wzHGmJiycz25xOzZs/n73//OoUOHKF68OF9//bUlIWNMgWCJyGf79u3j9ttvp0WLFvzyyy/89tupXQAYY0x+ZonIR59//jl16tThtddeY+DAgaxcuZJatWr5HZYxxuQou0bkE1XlmWeeoUyZMnzyySc0adLE75CMMcYXlohykKoyadIkLr/8cqpUqcIHH3xA2bJlKVq0qN+hGWOMb+zUXA5JTEykTZs2dOnShRdeeAGAM844w5KQMabAsyOiGEtOTmb8+PEMGjSI48eP8+yzz9K/f3+/wzLGmFzDjohi7Omnn6ZPnz40atSIFStWcM899xAXF+d3WMYYk2vYEVEMJCUl8ccff3DGGWfQq1cvzjjjDHr06IFIqF7PjTGmYLMjoihbtWoVl1xySZoipbfeeqslIWOMCcMSUZT8+eefPP744zRq1IgNGzZwzz33WJFSY4yJgJ2ai4KNGzfSunVrVq9eTdeuXRk1ahQVKlTwOyxjjMkTbJc9CipXrkzlypWZNm0a7777riUhY4zJBEtEWTRr1iyuvPJKDh48SPHixZk5cyatWrXyOyxjjMlzLBFl0t69e+nVqxdXXnklv/32G4mJiX6HZIwxeZolokz49NNPqVOnDq+//jqDBg1ixYoV/PWvf/U7LGOMydOssUKEVJXnnnuOChUqMHXqVBo3bux3SMYYky9YIkqHqjJhwgSaN2+eWqS0TJkyVh/OGGOiyLdTcyJSTkRmisjP3v+yYabbJCIrRWSZiCzKqfg2b95Mq1at6Nq1Ky+++CIAp59+uiUhY4yJMj+vEQ0GvlbV84CvvefhtFDVBqoa8/NhycnJvPzyy9SpU4fZs2czatQohg4dGuvFGmNMgeVnIroBeMt7/BbQ1sdYUg0fPpw77riDJk2asGrVKvr3729FSo0xJob8vEZ0hqpuA1DVbSJyepjpFPhSRBR4RVVfDTWRiPQGegOcddZZWQ6qT58+VKlShVtuucXqwxljTA4QVY3dzEW+AiqFGPUQ8JaqlgmYdo+qnnKdSESqqOpWL1HNBP6lqnPTW27jxo110aIcu5xkjDH5gogszolLIMFiekSkqleFGyci20Wksnc0VBnYEWYeW73/O0RkMtAESDcRGWOMyTv8vEb0KXCL9/gWYGrwBCJSUkQSUh4DfwdW5ViExhhjYs7PRDQcuFpEfgau9p4jIlVEZLo3zRnANyKyHFgAfK6qX/gSrTHGmJjwrbGCqu4CrgwxfCtwnfd4A1A/h0MzxhiTg6zWnDHGGF9ZIjLGGOMrS0TGGGN8ZYnIGGOMr2J6Q6tfRGQn8Gs2ZlEB+CNK4fgpv6wH2LrkVvllXfLLekD21qW6qlaMZjCRyJeJKLtEZJEfdxdHW35ZD7B1ya3yy7rkl/WAvLkudmrOGGOMrywRGWOM8ZUlotBCVvjOg/LLeoCtS26VX9Ylv6wH5MF1sWtExhhjfGVHRMYYY3xlicgYY4yvLBEBIlJORGaKyM/e/1M66POm2yQiK0VkmYjkmp73ROQaEflJRNaLyOAQ40VEXvDGrxCRRn7EGYkI1qW5iOzzPoNlIvKoH3FmREReF5EdIhKy25I89plktC555TM5U0T+JyJrRWS1iPQPMU2e+FwiXJc88bkAoKoF/g94BhjsPR4MPB1muk3A/7d39yFWVGEcx78/UlFUkBK1rFDDKBXRTcWSQsP8wwILNQ0qkSLUioyKRKms/jEMw4iQXiQN8y01TTQrTBCpdcl0d2PNVJbclCyjfEkK7emPObdut/syu647d7rPB+SemTln5jk8u3t2Zsdzuicdb05MlwCHgH5AB2AfMCCnznhgKyBgJFCddNwX0JfRwOakY43Rl1uAKqC+wPFU5CRmX9KSk8uBqlDuChxI8fdKnL6kIi9m5ndEwQRgWSgvA+5MMJbmGgEcNLPDZvYHsIqoP9kmAMst8gXQLayKW27i9CUVLFrO/uciVdKSkzh9SQUzO2Zme0L5FNAA9M6ploq8xOxLavhAFOlpZscgSjDQo0A9Az6W9KWkh9osuuJ6A0eytpv47xdknDrlIG6cN0raJ2mrpIFtE1qrS0tO4kpVTiT1AYYC1TmHUpeXIn2BlOQlsYXx2pqkT4FeeQ7Na8ZpRpnZUUk9gE8k7Q+/LSZJefblvpMfp045iBPnHqL5sE5LGg98APS/6JG1vrTkJI5U5URSF2AdMNvMTuYeztOkbPNSoi+pyUvF3BGZ2VgzG5Tn30bgh8ztd/g8XuAcR8PncWAD0aOkpDUBV2VtXwkcbUGdclAyTjM7aWanQ3kL0F5S97YLsdWkJSclpSknktoT/eBeYWbr81RJTV5K9SVNeamYgaiETcC0UJ4GbMytIKmzpK6ZMjAOyPsWURurAfpL6iupAzCVqD/ZNgH3hzeCRgK/Zh5FlpmSfZHUS5JCeQTR1/CJNo/0wqUlJyWlJSchxreBBjNbVKBaKvISpy9pyQtU0KO5EhYAayQ9AHwHTAaQdAXwlpmNB3oCG0Je2wHvmdlHCcX7NzM7J+kRYBvRW2dLzexrSTPC8SXAFqK3gQ4CvwHTk4q3mJh9mQTMlHQOOAtMtfCKUDmRtJLoraXukpqA54D2kK6cQKy+pCInwCjgPqBO0t6wby5wNaQuL3H6kpa8+BQ/zjnnkuWP5pxzziXKByLnnHOJ8oHIOedconwgcs45lygfiJxzziXKByLnnHOJ8oHI/e9JMknvZm23k/SjpM1F2oyWdFMLrtVN0qyc8xS8TktJekfSpNY+r3NJ8IHIVYIzwCBJncL2bcD3JdqMBvIORJKK/UfwbsCsIsedczl8IHKVYitweyjfA6wsVDHMZjwDeDwsKHZzuANZJOkz4CVJ8yU9mdWmPrRbAFwT2i0Mh7tIel/SfkkrMtOuZLW9XtLu7OtLqg3lZyXVhPO/kds21GnMzCEmaZikHaHcWdGidjWSvpI0IewfKGl3iLFWUllOhOkqhw9ErlKsAqZK6ggMJv+U+QCYWSOwBHjFzIaY2c5w6FpgrJk9UeQ6c4BDod1TYd9QYDYwgGjRv1E512sAOkjqF3ZNAdaE8mtmNtzMBgGdgDti9TYyD9huZsOBMcDCME/iDGCxmQ0BhhFN9OlcYnwgchXBzGqBPkR3Q1taeJq1Zna+Be12m1mTmf0J7A1x5FoD3B3KU4DVoTxGUrWkOuBWoDlryowD5oS5yHYAHYnmIvscmCvpaaJlAs42sz/OtSqf9NRVkk3Ay0R//7msBe3PZJXP8e9f5DoWafd7Vvk8+b/vVgNrJa0HzMy+DXdvrwPDzOyIpPkFrpMdS/ZxARPN7Juc+g2SqokeVW6T9KCZbS8Sv3MXld8RuUqyFHjBzOpi1D0FdC1yvBGoApBUBfSN2S4vMztENEg9wz93Q5lB5SdFC6AVekuuEbghlCdm7d8GPJq1FMDQ8NkPOGxmrxINzoObG69zrckHIlcxwuOxxTGrfwjclXlZIc/xdcCl4bHXTOBAuMYJYFd4uWBhnnbFrAbuJfx9yMx+Ad4E6ohW16wp0O55YLGknUSDWcaLRMs11EqqD9sQPfqrD7FfByxvZpzOtSpfBsI551yi/I7IOedcovxlBVfRJE0HHsvZvcvMHk4iHucqkT+ac845lyh/NOeccy5RPhA555xLlA9EzjnnEuUDkXPOuUT9BV0ZkEANFTTbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_SingleValuePerImg_augmented ,ds_test=custom_DS_SingleValuePerImg_test ,phase_name='single_gene_augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: K genes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.683421716094017\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.043366709037831\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.904226440740259\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getKDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015, 10)  ~  M_truth.shape (4015, 10)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 433.3573307098388\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 1min 34s, sys: 8.07 s, total: 1min 42s\n",
      "Wall time: 2min 37s\n",
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 3.250675279451044\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.9538310158409571\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.8887701767839884\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getKDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015, 10)  ~  M_truth.shape (4015, 10)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 410.7317486710929\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 4min 12s, sys: 19.3 s, total: 4min 31s\n",
      "Wall time: 5min 52s\n",
      "\n",
      "finished experiment DensetNet121\n"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_KGenesWithHighestVariance ,ds_test=custom_DS_KGenesWithHighestVariance_test ,phase_name='k_genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.1920923530078325\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.8629033511046503\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.6593030682108442\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getKDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015, 10)  ~  M_truth.shape (4015, 10)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 440.84960663747256\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 10min 10s, sys: 51.6 s, total: 11min 2s\n",
      "Wall time: 17min 17s\n",
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.1458272373334306\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.682559122536026\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.6061353593820431\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getKDimPrediction -----\n",
      "--delete-- verify:  M_pred.shape (4015, 10)  ~  M_truth.shape (4015, 10)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 422.8133016316638\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 29min 19s, sys: 1min 58s, total: 31min 18s\n",
      "Wall time: 40min 20s\n",
      "Parser   : 353 ms\n",
      "\n",
      "finished experiment DensetNet121\n"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_KGenesWithHighestVariance_augmented ,ds_test=custom_DS_KGenesWithHighestVariance_test ,phase_name='k_genes_augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: All genes prediction - using dimensionality reduction techniques\n",
    "\n",
    "### 4.1: Prediction using dimensionality reduction technique NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.9715351260169164\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.11062219447309249\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.1092799044165172\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 3813)\n",
      "--delete-- verify:  M_pred.shape (18077, 3813)  ~  M_truth.shape (18077, 3813)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "distance between M_truth, M_pred: 4844.975493786701\n",
      "distance between M_truth, M_fast_reconstruction: 2628.8781186696665\n",
      "distance between M_pred, M_fast_reconstruction: 4069.689881636407\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 4015)\n",
      "--delete-- verify:  M_pred.shape (18077, 4015)  ~  M_truth.shape (18077, 4015)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 4906.09366683848\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 2min 10s, sys: 42.9 s, total: 2min 53s\n",
      "Wall time: 2min 55s\n",
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.06921659571755874\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.060277033082552646\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.05570744448586514\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 3813)\n",
      "--delete-- verify:  M_pred.shape (18077, 3813)  ~  M_truth.shape (18077, 3813)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "distance between M_truth, M_pred: 3570.1172585253403\n",
      "distance between M_truth, M_fast_reconstruction: 2628.8781186696665\n",
      "distance between M_pred, M_fast_reconstruction: 2409.2425005586397\n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 4015)\n",
      "--delete-- verify:  M_pred.shape (18077, 4015)  ~  M_truth.shape (18077, 4015)\n",
      "\n",
      "----- finished function getKDimPrediction -----\n",
      "TODO: print comparison of error results\n",
      "recieved M_fast_reconstruction=None. errors with it will be 0\n",
      "distance between M_truth, M_pred: 3528.341831845168\n",
      "distance between M_truth, M_fast_reconstruction: 0\n",
      "distance between M_pred, M_fast_reconstruction: 0\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n",
      "CPU times: user 5min 4s, sys: 47.6 s, total: 5min 52s\n",
      "Wall time: 6min 20s\n",
      "\n",
      "finished experiment DensetNet121\n"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_NMF ,ds_test=custom_DS_LatentTensor_NMF_test ,phase_name='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.14525805357843638\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.09649317733271688\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.084102328463656\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 30504)\n",
      "--delete-- verify:  M_pred.shape (18077, 30504)  ~  M_truth.shape (18077, 3813)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(ds_train, ds_test, hyperparams, device, model_name, dataset_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NMF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mM_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFullDimsPrediction_with_NMF_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# train-error comparisons: M_truth ~ M_fast_reconstruction ~ M_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m#                      orig_matrix ~       W * H           ~ W * H_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mgetFullDimsPrediction_with_NMF_DS\u001b[0;34m(dataset, W, model, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mM_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mM_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mM_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.05743554156945377\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.048477902628298174\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 0.044420166403726966\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_NMF_DS -----\n",
      "--delete-- verify: W_prepared.shape (18077, 10), y_pred_prepared.shape (10, 30504)\n",
      "--delete-- verify:  M_pred.shape (18077, 30504)  ~  M_truth.shape (18077, 3813)\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(ds_train, ds_test, hyperparams, device, model_name, dataset_name)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NMF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0mM_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetFullDimsPrediction_with_NMF_DS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0;31m# train-error comparisons: M_truth ~ M_fast_reconstruction ~ M_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;31m#                      orig_matrix ~       W * H           ~ W * H_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mgetFullDimsPrediction_with_NMF_DS\u001b[0;34m(dataset, W, model, device)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mM_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0mM_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mM_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished experiment DensetNet121\n"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_NMF_augmented ,ds_test=custom_DS_LatentTensor_NMF_test ,phase_name='NMF_augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Prediction using dimensionality reduction technique AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 2.5388931192849813\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.9609106194816137\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.7250897123625404\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_AE_DS -----\n",
      "printing information about the dataset:\n",
      "size of the dataset (==number of images in the image folder) 3813\n",
      "num_of_samples_matrix_df in the dataset (==number of columns in matrix_dataframe) 3813\n",
      "num_of_features_matrix_df in the dataset (==number of rows in matrix_dataframe) 18077\n",
      "--delete-- verify:  M_pred.shape (18077, 3813)  ~  M_truth.shape (18077, 3813)\n",
      "\n",
      "----- finished function getFullDimsPrediction_with_AE_DS -----\n",
      "\n",
      "----- entered function getAutoEncoder_M_fast_reconstruction -----\n",
      "batch 3813 of 3813 batches\r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(ds_train, ds_test, hyperparams, device, model_name, dataset_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# train-error comparisons: M_truth ~ M_fast_reconstruction ~ M_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#                      orig_matrix ~  Decode(Encode(M))    ~ Decode(Predict(X))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mM_fast_reconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAutoEncoder_M_fast_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mcompare_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_fast_reconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mgetAutoEncoder_M_fast_reconstruction\u001b[0;34m(dataset, model, device)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;31m# assert equal sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mM_fast_reconstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n----- finished function getAutoEncoder_M_fast_reconstruction -----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished experiment BasicConvNet\n",
      "\n",
      "starting experiment **DensetNet121**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 2.750806599855423\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.7471459774594558\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 152 of 152 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.609512571049364\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_AE_DS -----\n",
      "printing information about the dataset:\n",
      "size of the dataset (==number of images in the image folder) 3813\n",
      "num_of_samples_matrix_df in the dataset (==number of columns in matrix_dataframe) 3813\n",
      "num_of_features_matrix_df in the dataset (==number of rows in matrix_dataframe) 18077\n",
      "--delete-- verify:  M_pred.shape (18077, 3813)  ~  M_truth.shape (18077, 3813)\n",
      "\n",
      "----- finished function getFullDimsPrediction_with_AE_DS -----\n",
      "\n",
      "----- entered function getAutoEncoder_M_fast_reconstruction -----\n",
      "batch 3813 of 3813 batches\r"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(ds_train, ds_test, hyperparams, device, model_name, dataset_name)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;31m# train-error comparisons: M_truth ~ M_fast_reconstruction ~ M_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m#                      orig_matrix ~  Decode(Encode(M))    ~ Decode(Predict(X))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mM_fast_reconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetAutoEncoder_M_fast_reconstruction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrained_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0mcompare_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM_truth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM_fast_reconstruction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mgetAutoEncoder_M_fast_reconstruction\u001b[0;34m(dataset, model, device)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;31m# assert equal sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mM_fast_reconstruction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatrix_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n----- finished function getAutoEncoder_M_fast_reconstruction -----\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finished experiment DensetNet121\n"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_AE ,ds_test=custom_DS_LatentTensor_AE_test ,phase_name='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "starting experiment **BasicConvNet**\n",
      "\n",
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.9661790026015922\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.513339985003237\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 1220 of 1220 batches\n",
      "finished inner loop.\n",
      "in this epoch: average loss 1.0845200430418624\n",
      "finished all epochs !\n",
      "which means, that this model is now trained.\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function getFullDimsPrediction_with_AE_DS -----\n",
      "printing information about the dataset:\n",
      "size of the dataset (==number of images in the image folder) 30504\n",
      "num_of_samples_matrix_df in the dataset (==number of columns in matrix_dataframe) 3813\n",
      "num_of_features_matrix_df in the dataset (==number of rows in matrix_dataframe) 18077\n",
      "batch 11239 of 30504 batches\r"
     ]
    }
   ],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_AE_augmented ,ds_test=custom_DS_LatentTensor_AE_test ,phase_name='AE_augmented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note:</b> testing blocks\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
