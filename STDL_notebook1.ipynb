{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****STDL PROJECT NOTEBOOK****\n",
    "\n",
    "**Phase 1: predict gene expression levels of one specific gene over given input biopsy images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import project files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "import loadAndPreProcess\n",
    "import deepNetworkArchitechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce RTX 2080 Ti\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7f97fc191d90>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform pre processing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi! welcome to the program :)\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset -----\n",
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you wish to print information about the ImageFolder dataset object ? [yes/no] n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you wish to print information about the 3 loaded dataframes ? [yes/no] n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHi! welcome to the program :)\\n\")\n",
    "\n",
    "path_to_images_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/images\"\n",
    "path_to_mtx_tsv_files_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData\"\n",
    "gene_name = 'MKI67'\n",
    "stdl_ds = loadAndPreProcess.STDL_Dataset(path_to_images_dir=path_to_images_dir,\n",
    "                                      path_to_mtx_tsv_files_dir=path_to_mtx_tsv_files_dir,\n",
    "                                      chosen_gene_name=gene_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "display a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code to display some sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform the first test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runTest1 -----\n",
      "verify size of ds_train 3000\n",
      "verify size of ds_test 813\n",
      "verify size of dl_train 120\n",
      "verify size of dl_test 33\n",
      "verify im_size torch.Size([3, 176, 176])\n",
      "verify size of dl_test 33\n",
      "verify batch_size is 25 \n",
      "A single image's shape will be like x0.shape : torch.Size([3, 176, 176])\n",
      "A single image's shape will be like x0.shape - after unsqueeze : torch.Size([1, 3, 176, 176])\n",
      "verify in_size torch.Size([3, 176, 176])\n",
      "note - number of convolutions is supposed to be 1\n",
      "note - number of (hidden) linear layers is supposed to be 1\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 10 epochs\n",
      "assert: len(y) 25 == len(y_pred_rounded) 25\n",
      "assert: y.shape torch.Size([25]) == y_pred.shape torch.Size([25, 1]) != == y_pred_rounded.shape torch.Size([25])\n",
      "testing: y.unsqueeze(0) shape is: torch.Size([1, 25]) \n",
      "\n",
      "testing: y.unsqueeze(1) shape is: torch.Size([25, 1]) \n",
      "\n",
      "testing: y.unsqueeze(-1) shape is: torch.Size([25, 1]) \n",
      "\n",
      "ground truth y is: tensor([1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 4, 0, 0,\n",
      "        0], device='cuda:0') \n",
      "\n",
      "prediction y rounded is: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0], device='cuda:0', dtype=torch.int32) \n",
      "\n",
      "\n",
      "return to normal\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e01d1672f5d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecutionModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mexecutionModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunTest1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstdl_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunTest1\u001b[0;34m(dataset, device)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# Compute (and print) loss.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# todo: check order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0mloss_values_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0;31m# Before the backward pass, use the optimizer object to zero all of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import executionModule\n",
    "\n",
    "executionModule.runTest1(stdl_ds, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
