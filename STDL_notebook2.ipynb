{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****STDL PROJECT NOTEBOOK****\n",
    "\n",
    "**Phase 1: predict gene expression levels of one specific gene over given input biopsy images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda debugging allowed\n"
     ]
    }
   ],
   "source": [
    "# the next 2 lines are to allow debugging with CUDA !\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  \n",
    "print(f'cuda debugging allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce RTX 2080\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7f756df8fbd0>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "# NOTE: important !!!!!!\n",
    "# clearing out the cache before beginning\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Import project files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "import loadAndPreProcess\n",
    "import deepNetworkArchitechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform pre processing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi! welcome to the program :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHi! welcome to the program :)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_images_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/images\"\n",
    "imageFolder = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_images_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/images\"\n",
    "augmentedImageFolder = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_mtx_tsv_files_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData\"\n",
    "matrix_dataframe, features_dataframe, barcodes_datafame = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove empty genes (i think there are only 3 of these ... need to verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting all genes (rows) that contain only zeros ...\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "matrix_dataframe, mapping_between_old_and_new_indices = loadAndPreProcess.cut_empty_genes(matrix_dataframe)  #TODO: uncomment later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if wanted\n",
    "# print(f'\\note: this is the mapping_between_old_and_new_indices: \\n{mapping_between_old_and_new_indices}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create all of the custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gene_name = 'MKI67'\n",
    "custom_DS_SingleValuePerImg = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder, \n",
    "                                                               matrix_dataframe=matrix_dataframe, \n",
    "                                                               features_dataframe=features_dataframe, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name)\n",
    "custom_DS_SingleValuePerImg_augmented = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=augmentedImageFolder, \n",
    "                                                               matrix_dataframe=matrix_dataframe, \n",
    "                                                               features_dataframe=features_dataframe, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "custom_DS_KGenesWithHighestVariance = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "custom_DS_LatentTensor_NMF = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "--delete-- verify inside STDL_Dataset_matrix_df_for_AE_init __init__: self.data.shape: (23073, 4992)\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003137960797175765 max loss 2806.05908203125\n",
      "               average loss 10.52984281306402\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00298705929890275 max loss 2733.376953125\n",
      "               average loss 7.655813598069542\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003660012036561966 max loss 1233.6768798828125\n",
      "               average loss 6.256867509540778\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "--delete-- verify inside STDL_Dataset_matrix_df_for_AE_init __init__: self.data.shape: (23073, 4992)\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003149256808683276 max loss 2819.2451171875\n",
      "               average loss 10.454374120836665\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003079331247135997 max loss 2196.147216796875\n",
      "               average loss 7.709718835036396\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 4992 of 4992 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003104463219642639 max loss 555.8245849609375\n",
      "               average loss 6.215676063456274\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_AE = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "display a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code to display some sample images\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check sizes of a pair (x,y) from all different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'custom_DS_SingleValuePerImg (single gene):      x shape {custom_DS_SingleValuePerImg[0][0].shape}, y is an int')\n",
    "# print(f'custom_DS_SingleValuePerImg_augmented:          x shape {custom_DS_SingleValuePerImg_augmented[0][0].shape}, y is an int')\n",
    "# print(\"---------\")\n",
    "# print(f'custom_DS_KGenesWithHighestVariance:            x shape {custom_DS_KGenesWithHighestVariance[0][0].shape}, y shape {custom_DS_KGenesWithHighestVariance[0][1].shape}')\n",
    "# print(f'custom_DS_KGenesWithHighestVariance_augmented:  x shape {custom_DS_KGenesWithHighestVariance_augmented[0][0].shape}, y shape {custom_DS_KGenesWithHighestVariance_augmented[0][1].shape}')\n",
    "# print(\"---------\")\n",
    "# print(f'custom_DS_LatentTensor_NMF:                     x shape {custom_DS_LatentTensor_NMF[0][0].shape}, y shape {custom_DS_LatentTensor_NMF[0][1].shape}')\n",
    "# print(f'custom_DS_LatentTensor_NMF_augmented:           x shape {custom_DS_LatentTensor_NMF_augmented[0][0].shape}, y shape {custom_DS_LatentTensor_NMF_augmented[0][1].shape}')\n",
    "# print(\"---------\")\n",
    "# print(f'custom_DS_LatentTensor_AE:                      x shape {custom_DS_LatentTensor_AE[0][0].shape}, y shape {custom_DS_LatentTensor_AE[0][1].shape}')\n",
    "# print(f'custom_DS_LatentTensor_AE_augmented:            x shape {custom_DS_LatentTensor_AE_augmented[0][0].shape}, y shape {custom_DS_LatentTensor_AE_augmented[0][1].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import executionModule\n",
    "\n",
    "# define hyperparameters for the experiments\n",
    "hyperparameters = dict()\n",
    "hyperparameters['batch_size'] = 25\n",
    "hyperparameters['max_alowed_number_of_batches'] = 99999\n",
    "hyperparameters['precent_of_dataset_allocated_for_training'] = 0.8\n",
    "hyperparameters['learning_rate'] = 1e-4\n",
    "hyperparameters['num_of_epochs'] = 3\n",
    "hyperparameters['channels'] = [32] \n",
    "hyperparameters['num_of_convolution_layers'] = len(hyperparameters['channels'])\n",
    "hyperparameters['hidden_dims'] = [100]\n",
    "hyperparameters['num_of_hidden_layers'] = len(hyperparameters['hidden_dims'])\n",
    "hyperparameters['pool_every'] = 99999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests without having to restore the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0001819812459871173 max loss 396.0445556640625\n",
      "               average loss 3.610258524980397\n",
      "               number of correct predictions: 2542 / 3050\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.000150407780893147 max loss 0.04182210564613342\n",
      "               average loss 0.0025663093975544756\n",
      "               number of correct predictions: 3044 / 3050\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 4.602078479365446e-05 max loss 0.06566838920116425\n",
      "               average loss 0.002245412715995774\n",
      "               number of correct predictions: 3044 / 3050\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_SingleValuePerImg, hyperparams=hyperparameters, device=device, dataset_name='single_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 9.504583431407809e-05 max loss 306.73480224609375\n",
      "               average loss 0.6752635390472039\n",
      "               number of correct predictions: 11988 / 12200\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00044289272045716643 max loss 0.06536505371332169\n",
      "               average loss 0.004903169534551781\n",
      "               number of correct predictions: 12182 / 12200\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0009261455852538347 max loss 0.057041049003601074\n",
      "               average loss 0.007741274036844948\n",
      "               number of correct predictions: 12183 / 12200\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_SingleValuePerImg_augmented, hyperparams=hyperparameters, device=device, dataset_name='single_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 7084.02294921875 max loss 263481.53125\n",
      "               average loss 28833.73088899206\n",
      "               number of correct predictions: 127 / 3050\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 6378.60595703125 max loss 263565.65625\n",
      "               average loss 27522.503514024076\n",
      "               number of correct predictions: 134 / 3050\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 6949.02685546875 max loss 272018.625\n",
      "               average loss 27205.465340035862\n",
      "               number of correct predictions: 136 / 3050\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_KGenesWithHighestVariance, hyperparams=hyperparameters, device=device, dataset_name='highest_variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 6970.97021484375 max loss 300416.125\n",
      "               average loss 30164.106305231813\n",
      "               number of correct predictions: 525 / 12200\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 7150.82666015625 max loss 262412.875\n",
      "               average loss 29239.395074562948\n",
      "               number of correct predictions: 532 / 12200\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 6257.8837890625 max loss 269298.78125\n",
      "               average loss 28640.814985431607\n",
      "               number of correct predictions: 531 / 12200\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_KGenesWithHighestVariance_augmented, hyperparams=hyperparameters, device=device, dataset_name='highest_variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests that restore the dimensions after training (for now, only for 1 sample image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.4740532338619232 max loss 28.61026382446289\n",
      "               average loss 2.210003663037644\n",
      "               number of correct predictions: 21736 / 3050\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.40272819995880127 max loss 5.3211870193481445\n",
      "               average loss 1.8099468677747446\n",
      "               number of correct predictions: 23571 / 3050\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.312259703874588 max loss 5.488589286804199\n",
      "               average loss 1.799050134469251\n",
      "               number of correct predictions: 23637 / 3050\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function runDimensionalityRestorationExperiment_with_NMF_DS -----\n",
      "Verification of W,H matrices:\n",
      "W len 23073\n",
      "W type <class 'numpy.ndarray'>\n",
      "W shape (23073, 10)\n",
      "H len 10\n",
      "H len <class 'numpy.ndarray'>\n",
      "H shape (10, 4992)\n",
      " and so: W*H = (23073, 10)*(10, 4992) should give us the right format\n",
      "corret prediction after dimensionality restoration: 19178 out of 23073\n",
      "\n",
      "----- finished function runDimensionalityRestorationExperiment_with_NMF_DS -----\n",
      "\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_NMF, hyperparams=hyperparameters, device=device, dataset_name='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp to delete ?\n",
    "# model = executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_NMF, hyperparams=hyperparameters, device=device, dataset_name='NMF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp to delete ?\n",
    "# executionModule.runDimensionalityRestorationExperiment_with_NMF_DS(dataset=custom_DS_LatentTensor_NMF, model=model, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.4157313406467438 max loss 41.11117935180664\n",
      "               average loss 1.5334972513259435\n",
      "               number of correct predictions: 72896 / 12200\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.33475929498672485 max loss 4.769974708557129\n",
      "               average loss 1.261106010953911\n",
      "               number of correct predictions: 83461 / 12200\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.3777877688407898 max loss 4.974216938018799\n",
      "               average loss 1.2144007431801225\n",
      "               number of correct predictions: 83999 / 12200\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function runDimensionalityRestorationExperiment_with_NMF_DS -----\n",
      "Verification of W,H matrices:\n",
      "W len 23073\n",
      "W type <class 'numpy.ndarray'>\n",
      "W shape (23073, 10)\n",
      "H len 10\n",
      "H len <class 'numpy.ndarray'>\n",
      "H shape (10, 4992)\n",
      " and so: W*H = (23073, 10)*(10, 4992) should give us the right format\n",
      "corret prediction after dimensionality restoration: 19216 out of 23073\n",
      "\n",
      "----- finished function runDimensionalityRestorationExperiment_with_NMF_DS -----\n",
      "\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_NMF_augmented, hyperparams=hyperparameters, device=device, dataset_name='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1828.24853515625 max loss 39748.41015625\n",
      "               average loss 5455.717826468046\n",
      "               number of correct predictions: 235 / 3050\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1396.4315185546875 max loss 42641.01953125\n",
      "               average loss 4962.503476002177\n",
      "               number of correct predictions: 285 / 3050\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1855.9151611328125 max loss 40247.640625\n",
      "               average loss 4845.142832271388\n",
      "               number of correct predictions: 300 / 3050\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function runDimensionalityRestorationExperiment_with_AE_DS -----\n",
      "corret prediction after dimensionality restoration: 14874 out of 23073\n",
      "\n",
      "----- finished function runDimensionalityRestorationExperiment_with_AE_DS -----\n",
      "\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_AE, hyperparams=hyperparameters, device=device, dataset_name='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp to delete ?\n",
    "# model = executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_AE, hyperparams=hyperparameters, device=device, dataset_name='AE')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp to delete ?\n",
    "# executionModule.runDimensionalityRestorationExperiment_with_AE_DS(dataset=custom_DS_LatentTensor_AE, model=model, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function runExperimentWithModel_BasicConvNet -----\n",
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 3\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1491.4306640625 max loss 57165.2421875\n",
      "               average loss 5621.374486204054\n",
      "               number of correct predictions: 940 / 12200\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1556.7047119140625 max loss 56755.69921875\n",
      "               average loss 5372.164320898838\n",
      "               number of correct predictions: 988 / 12200\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 1446.34912109375 max loss 53031.10546875\n",
      "               average loss 5203.387615266393\n",
      "               number of correct predictions: 1030 / 12200\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n",
      "\n",
      "----- entered function runDimensionalityRestorationExperiment_with_AE_DS -----\n",
      "corret prediction after dimensionality restoration: 17174 out of 23073\n",
      "\n",
      "----- finished function runDimensionalityRestorationExperiment_with_AE_DS -----\n",
      "\n",
      "\n",
      "----- finished function runExperimentWithModel_BasicConvNet -----\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_LatentTensor_AE_augmented, hyperparams=hyperparameters, device=device, dataset_name='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
