{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spatial Transcriptomics Deep Learning (STDL) Project Notebook**\n",
    "\n",
    "> The notebook contains main experiments and examples of how to use the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Phase 1: Pre-processing and technical preparations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: **Assign GPU device and allow CUDA debugging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda debugging allowed\n"
     ]
    }
   ],
   "source": [
    "# the next 2 lines are to allow debugging with CUDA !\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  \n",
    "print(f'cuda debugging allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce GTX 1080 Ti\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7f0fef4f6b50>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "CPU times: user 1.1 s, sys: 2.8 s, total: 3.9 s\n",
      "Wall time: 5.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "# NOTE: important !!!!!!\n",
    "# clearing out the cache before beginning\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: **Import some of the project modules (more will be loaded later)**\n",
    "\n",
    "> `loadAndPreProcess` module contains methods to load the data files as pytorch and pandas objects, methods to preprocess the given data, and methods to create custom datasets from the preprocessed data.\n",
    "\n",
    "> `deepNetworkArchitechture` module contains .... write this :sad:  :\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>TODO:</b> fill above line\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "import loadAndPreProcess\n",
    "import deepNetworkArchitechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3: **Load pytorch dataset objects from the image folder**\n",
    "\n",
    "> Note that `augmentedImageFolder` is a custom dataset of imageFolder objects with different transformations (see code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 203 ms, sys: 130 ms, total: 333 ms\n",
      "Wall time: 1.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1/images\"\n",
    "imageFolder_train = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient1_train)\n",
    "augmentedImageFolder_train = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n",
      "CPU times: user 49.2 ms, sys: 93.2 ms, total: 142 ms\n",
      "Wall time: 767 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_images_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2/images\"\n",
    "imageFolder_test = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir_patient2_test)\n",
    "# augmentedImageFolder_test = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir_patient2_test) # not needed for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4: **Load pandas dataframe objects from the 3 given tsv/csv files**\n",
    "\n",
    "> `matrix_dataframe` represents the gene expression count values of each sample for each gene\n",
    "\n",
    "> `features_dataframe` contains the names of all the genes\n",
    "\n",
    "> `barcodes_datafame` contains the names of all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n",
      "CPU times: user 1min 23s, sys: 931 ms, total: 1min 24s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient1_train = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient1\"\n",
    "matrix_dataframe_train, features_dataframe_train , barcodes_datafame_train = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/loadAndPreProcess.py\u001b[0m in \u001b[0;36mload_dataframes_from_mtx_and_tsv_new\u001b[0;34m(path_to_mtx_tsv_files_dir)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"started reading matrix.mtx. this might take some time ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mpath_to_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_mtx_tsv_files_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/matrix.mtx\"\u001b[0m  \u001b[0;31m# TODO: note no gz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmmread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     matrix_dataframe = pd.DataFrame.sparse.from_spmatrix(\n\u001b[1;32m     51\u001b[0m         matrix)  # todo: note sure this works. from: https://pandas.pydata.org/docs/user_guide/sparse.html\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.7/site-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36mmmread\u001b[0;34m(source)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mMatrix\u001b[0m \u001b[0mMarket\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mMMFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;31m# -----------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.7/site-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_header\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.7/site-packages/scipy/io/mmio.py\u001b[0m in \u001b[0;36m_parse_body\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    616\u001b[0m                                      \"number of entries\")\n\u001b[1;32m    617\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m                 \u001b[0mI\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentry_number\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_pattern\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path_to_mtx_tsv_files_dir_patient2_test = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/patient2\"\n",
    "matrix_dataframe_test, features_dataframe_test , barcodes_datafame_test = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir_patient2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5: **Remove less-informative genes**\n",
    "\n",
    "> we define *less-informative* genes as genes with less than K counts over all samples\n",
    "\n",
    "> K is a parameter for the user's choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting all genes (rows) that contain only zeros ...\n",
      "\n",
      "print data regarding the reduced dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18484 entries, 0 to 18483\n",
      "Columns: 4992 entries, 0 to 4991\n",
      "dtypes: Sparse[int64, 0](4992)\n",
      "memory usage: 245.0 MB\n",
      "None\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4982  \\\n",
      "0     0     0     0     0     0     0     0     0     0     1  ...     0   \n",
      "1     0     0     0     2     0     0     0     0     0     0  ...     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   4983  4984  4985  4986  4987  4988  4989  4990  4991  \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     2     0  \n",
      "\n",
      "[5 rows x 4992 columns]\n",
      "\n",
      "min value in matrix_dataframe 0 max value in matrix_dataframe 5582\n",
      "\n",
      "median value in matrix_dataframe 0.0 mean value in matrix_dataframe 0.8196095900161747\n",
      "\n",
      "number of different values in matrix_dataframe is  1087 \n",
      "\n",
      "list of 10 most common values in matrix_dataframe is: \n",
      "1: the value 0 appeared 70861781 times (constitutes 76.79652% of the matrix values)\n",
      "2: the value 1 appeared 11137140 times (constitutes 12.06989% of the matrix values)\n",
      "3: the value 2 appeared 4169997 times (constitutes 4.51924% of the matrix values)\n",
      "4: the value 3 appeared 1993021 times (constitutes 2.15994% of the matrix values)\n",
      "5: the value 4 appeared 1100800 times (constitutes 1.19299% of the matrix values)\n",
      "6: the value 5 appeared 672858 times (constitutes 0.72921% of the matrix values)\n",
      "7: the value 6 appeared 444034 times (constitutes 0.48122% of the matrix values)\n",
      "8: the value 7 appeared 310903 times (constitutes 0.33694% of the matrix values)\n",
      "9: the value 8 appeared 227905 times (constitutes 0.24699% of the matrix values)\n",
      "10: the value 9 appeared 173612 times (constitutes 0.18815% of the matrix values)\n",
      "\n",
      "plotting a scatter plot of all values in matrix_dataframe (to see the distribution of values)\n",
      "CPU times: user 42 s, sys: 7.62 s, total: 49.7 s\n",
      "Wall time: 1min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Base_value = 10\n",
    "matrix_dataframe_train, mapping_between_old_and_new_indices_train = loadAndPreProcess.cut_genes_with_under_B_counts(matrix_dataframe_train, Base_value) \n",
    "# # uncomment if wanted:\n",
    "# print(f'\\nnote: this is the mapping_between_old_and_new_indices: \\n{mapping_between_old_and_new_indices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting all genes (rows) that contain only zeros ...\n",
      "\n",
      "print data regarding the reduced dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 18484 entries, 0 to 18483\n",
      "Columns: 4992 entries, 0 to 4991\n",
      "dtypes: Sparse[int64, 0](4992)\n",
      "memory usage: 245.0 MB\n",
      "None\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4982  \\\n",
      "0     0     0     0     0     0     0     0     0     0     1  ...     0   \n",
      "1     0     0     0     2     0     0     0     0     0     0  ...     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "4     0     0     0     1     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   4983  4984  4985  4986  4987  4988  4989  4990  4991  \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     0     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     2     0  \n",
      "\n",
      "[5 rows x 4992 columns]\n",
      "\n",
      "min value in matrix_dataframe 0 max value in matrix_dataframe 5582\n",
      "\n",
      "median value in matrix_dataframe 0.0 mean value in matrix_dataframe 0.8196095900161747\n",
      "\n",
      "number of different values in matrix_dataframe is  1087 \n",
      "\n",
      "list of 10 most common values in matrix_dataframe is: \n",
      "1: the value 0 appeared 70861781 times (constitutes 76.79652% of the matrix values)\n",
      "2: the value 1 appeared 11137140 times (constitutes 12.06989% of the matrix values)\n",
      "3: the value 2 appeared 4169997 times (constitutes 4.51924% of the matrix values)\n",
      "4: the value 3 appeared 1993021 times (constitutes 2.15994% of the matrix values)\n",
      "5: the value 4 appeared 1100800 times (constitutes 1.19299% of the matrix values)\n",
      "6: the value 5 appeared 672858 times (constitutes 0.72921% of the matrix values)\n",
      "7: the value 6 appeared 444034 times (constitutes 0.48122% of the matrix values)\n",
      "8: the value 7 appeared 310903 times (constitutes 0.33694% of the matrix values)\n",
      "9: the value 8 appeared 227905 times (constitutes 0.24699% of the matrix values)\n",
      "10: the value 9 appeared 173612 times (constitutes 0.18815% of the matrix values)\n",
      "\n",
      "plotting a scatter plot of all values in matrix_dataframe (to see the distribution of values)\n",
      "CPU times: user 41.6 s, sys: 2.88 s, total: 44.5 s\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "Base_value = 0\n",
    "matrix_dataframe_test, mapping_between_old_and_new_indices_test = loadAndPreProcess.cut_genes_with_under_B_counts(matrix_dataframe_train, Base_value) \n",
    "#TODO: note that this actually is not really needed, but it is to not change the functions inside this class to adjust to the test data\n",
    "\n",
    "# # uncomment if wanted:\n",
    "# print(f'\\nnote: this is the mapping_between_old_and_new_indices: \\n{mapping_between_old_and_new_indices}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6: **Normalize matrix_dataframe entries**\n",
    "\n",
    "> normaliztion will be performed on the remainning rows of the dataframe with the logic \"log 1P\"\n",
    "\n",
    "> This method Calculates log(1 + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 2.32 s, sys: 73.7 ms, total: 2.4 s\n",
      "Wall time: 3.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_train = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "performing log1P transformation of the dataframe ...\n",
      "\n",
      "CPU times: user 2.01 s, sys: 52.4 ms, total: 2.07 s\n",
      "Wall time: 2.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "matrix_dataframe_test = loadAndPreProcess.perform_log_1p_normalization(matrix_dataframe_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7: **Create custom datasets**\n",
    "\n",
    "> Each custom dataset is tailored per task\n",
    "\n",
    "> there are four tasks: single gene prediction, k gene prediction, all gene prediction using NMF dim. reduction, all gene prediction using AE dim. reduction\n",
    "\n",
    "> For each of the above tasks 2 datasets were created - one with the regular images, and one with the augmented dataset - images with transformations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'barcodes_datafame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'barcodes_datafame' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gene_name = 'MKI67'\n",
    "custom_DS_SingleValuePerImg = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder_train, \n",
    "                                                               matrix_dataframe=matrix_dataframe_train, \n",
    "                                                               features_dataframe=features_dataframe_train, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name,\n",
    "                                                               index_mapping=mapping_between_old_and_new_indices_train)\n",
    "custom_DS_SingleValuePerImg_augmented = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=augmentedImageFolder_train, \n",
    "                                                               matrix_dataframe=matrix_dataframe_train, \n",
    "                                                               features_dataframe=features_dataframe_train, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name,\n",
    "                                                               index_mapping=mapping_between_old_and_new_indices_train)\n",
    "custom_DS_SingleValuePerImg_test = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder_test, \n",
    "                                                               matrix_dataframe=matrix_dataframe_test, \n",
    "                                                               features_dataframe=features_dataframe_test, \n",
    "                                                               barcodes_datafame=barcodes_datafame_test, \n",
    "                                                               chosen_gene_name=gene_name,\n",
    "                                                               index_mapping=mapping_between_old_and_new_indices_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance` class, K genes with the highest variance are chosen from matrix_dataframe, and they are the only genes that are kept for training and testing purposes\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'reduced_df' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/loadAndPreProcess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, imageFolder, matrix_dataframe, features_dataframe, barcodes_datafame, num_of_dims_k)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mreduced_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_of_nlargest_indices\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# get k rows (genes) with highest variance over all of the columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         \u001b[0mreduced_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# this causes a new column to appear - \"index\" which contains the old indices before resetting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0mreduced_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"original_index_from_matrix_dataframe\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduced_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"original_index_from_matrix_dataframe\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'reduced_df' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_KGenesWithHighestVariance = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_train, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_train, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_test = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_test, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `STDL_Dataset_KValuesPerImg_LatentTensor_NMF` class, an NMF decompositionis performed on the matrix_dataframe object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'augmentedImageFolder_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'augmentedImageFolder_test' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_NMF = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_train, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_train, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_test, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> inside the init phase of `custom_DS_LatentTensor_AE` class, an Autoencoder network is being trained.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'barcodes_datafam_traine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'barcodes_datafam_traine' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_AE = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafam_traine, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder_train, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_train, \n",
    "                                                                           features_dataframe=features_dataframe_train, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_train, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder_test, \n",
    "                                                                           matrix_dataframe=matrix_dataframe_test, \n",
    "                                                                           features_dataframe=features_dataframe_test, \n",
    "                                                                           barcodes_datafame=barcodes_datafame_test, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8: prepare for the next phases in which the experiments are executed\n",
    "\n",
    "> import `executionModule` which contains the experiments, training methods, and testing methods\n",
    "\n",
    "> create `hyperparameters` dictionary which will contain all of the hyper-parameters for our experiments (note - user can change these later)\n",
    "\n",
    "> create `experiment_model_list` that will hold all the experiment methods in which the stated model is used for the experiment's execution\n",
    "\n",
    "> model_list\n",
    "\n",
    "> assisting function\n",
    "\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Warning:</b> change the hyper-parameters below with caution if needed !\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'executionModule' has no attribute 'runExperimentWithModel_BasicConvNet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'executionModule' has no attribute 'runExperimentWithModel_BasicConvNet'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import executionModule\n",
    "\n",
    "# define hyperparameters for the experiments\n",
    "hyperparameters = dict()\n",
    "hyperparameters['batch_size'] = 25\n",
    "hyperparameters['max_alowed_number_of_batches'] = 99999\n",
    "hyperparameters['precent_of_dataset_allocated_for_training'] = 0.8\n",
    "hyperparameters['learning_rate'] = 1e-4\n",
    "hyperparameters['momentum'] = 0.9\n",
    "hyperparameters['num_of_epochs'] = 3\n",
    "hyperparameters['channels'] = [32] \n",
    "hyperparameters['num_of_convolution_layers'] = len(hyperparameters['channels'])\n",
    "hyperparameters['hidden_dims'] = [100]\n",
    "hyperparameters['num_of_hidden_layers'] = len(hyperparameters['hidden_dims'])\n",
    "hyperparameters['pool_every'] = 99999\n",
    "\n",
    "# TODO: not needed anymore ?\n",
    "experiment_model_list = []\n",
    "experiment_model_list.append(executionModule.runExperimentWithModel_BasicConvNet)\n",
    "experiment_model_list.append(executionModule.runExperimentWithModel_DenseNet121)\n",
    "# experiment_model_list.append(executionModule.runExperimentWithModel_InceptionV3) #TODO: still need to sort out input image size... !\n",
    "\n",
    "model_list = []\n",
    "model_list.append('BasicConvNet')\n",
    "model_list.append('DensetNet121')\n",
    "#model_list.append('Inception_V3')  #TODO: still need to sort out input image size... !\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note:</b> inception_v3 model isnt sorted out yet... gives\n",
    "    RuntimeError: Calculated padded input size per channel: (2 x 2). Kernel size: (5 x 5). Kernel size can't be greater than actual input size\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-18-19b04bd073ae>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-19b04bd073ae>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    print(f'\\nstarting experiment **{model_name}**\\n')\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def experiment_loop(ds_train,ds_test,phase_name):\n",
    "    for model_name in experiment_model_list:\n",
    "    print(f'\\nstarting experiment **{model_name}**\\n')\n",
    "    %time executionModule.runExperiment(ds_train=custom_DS_SingleValuePerImg,\n",
    "                                        ds_test=, \n",
    "                                        hyperparams=hyperparameters,\n",
    "                                        device=device, \n",
    "                                        model_name=model_name, \n",
    "                                        dataset_name=phase_name)\n",
    "    print(f'\\nfinished experiment {model_name}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Single Gene Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_SingleValuePerImg ,ds_test= ,phase_name='single_gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_SingleValuePerImg_augmented ,ds_test= ,phase_name='single_gene')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: K genes prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_KGenesWithHighestVariance ,ds_test= ,phase_name='k_genes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_KGenesWithHighestVariance_augmented ,ds_test= ,phase_name='k_genes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 4: All genes prediction - using dimensionality reduction techniques\n",
    "\n",
    "### 4.1: Prediction using dimensionality reduction technique NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_NMF ,ds_test= ,phase_name='NMF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_NMF_augmented ,ds_test= ,phase_name='NMF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1: Prediction using dimensionality reduction technique AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_AE ,ds_test= ,phase_name='AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_loop(ds_train=custom_DS_LatentTensor_AE_augmented ,ds_test= ,phase_name='AE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Note:</b> not tested yet\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
