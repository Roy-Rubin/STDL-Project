{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****STDL PROJECT NOTEBOOK****\n",
    "\n",
    "**Phase 1: predict gene expression levels of one specific gene over given input biopsy images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign GPU device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda debugging allowed\n"
     ]
    }
   ],
   "source": [
    "# the next 2 lines are to allow debugging with CUDA !\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"  \n",
    "print(f'cuda debugging allowed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda device count: 1\n",
      "Using device: cuda\n",
      "device name: GeForce RTX 2080 Ti\n",
      "torch.cuda.device(0): <torch.cuda.device object at 0x7fe4141d0c10>\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    }
   ],
   "source": [
    "######\n",
    "import torch\n",
    "print(f'cuda device count: {torch.cuda.device_count()}')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(f'device name: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'torch.cuda.device(0): {torch.cuda.device(0)}')\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')\n",
    "# NOTE: important !!!!!!\n",
    "# clearing out the cache before beginning\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Import project files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create code to reimport module if i change it\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# note: path to project is: /home/roy.rubin/STDLproject/\n",
    "import loadAndPreProcess\n",
    "import deepNetworkArchitechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform pre processing actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hi! welcome to the program :)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nHi! welcome to the program :)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_images_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/images\"\n",
    "imageFolder = loadAndPreProcess.load_dataset_from_images_folder(path_to_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataset_from_pictures_folder -----\n",
      "\n",
      "----- finished function load_dataset_from_pictures_folder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_images_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData/images\"\n",
    "augmentedImageFolder = loadAndPreProcess.load_augmented_imageFolder_DS_from_images_folder(path_to_images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entered function load_dataframes_from_mtx_and_tsv -----\n",
      "started reading features.tsv\n",
      "V  finished reading features.tsv\n",
      "started reading barcodes.tsv\n",
      "V  finished reading barcodes.tsv\n",
      "started reading matrix.mtx. this might take some time ...\n",
      "V  finished reading matrix.mtx\n",
      "\n",
      "----- finished function load_dataframes_from_mtx_and_tsv -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path_to_mtx_tsv_files_dir = \"/home/roy.rubin/STDLproject/spatialGeneExpressionData\"\n",
    "matrix_dataframe, features_dataframe, barcodes_datafame = loadAndPreProcess.load_dataframes_from_mtx_and_tsv_new(path_to_mtx_tsv_files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove empty genes (i think there are only 3 of these ... need to verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting all genes (rows) that contain only zeros ...\n",
      "\n",
      "print data regarding the reduced dataframe:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23073 entries, 0 to 23072\n",
      "Columns: 4992 entries, 0 to 4991\n",
      "dtypes: Sparse[int64, 0](4992)\n",
      "memory usage: 245.2 MB\n",
      "None\n",
      "   0     1     2     3     4     5     6     7     8     9     ...  4982  \\\n",
      "0     0     0     0     0     0     0     0     0     0     1  ...     0   \n",
      "1     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "2     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "3     0     0     0     2     0     0     0     0     0     0  ...     0   \n",
      "4     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
      "\n",
      "   4983  4984  4985  4986  4987  4988  4989  4990  4991  \n",
      "0     0     0     0     0     0     0     0     0     0  \n",
      "1     0     0     1     0     0     0     0     0     0  \n",
      "2     0     0     0     0     0     0     0     0     0  \n",
      "3     0     0     0     0     0     0     0     0     0  \n",
      "4     0     0     0     0     0     0     0     0     0  \n",
      "\n",
      "[5 rows x 4992 columns]\n",
      "\n",
      "min value in matrix_dataframe 0 max value in matrix_dataframe 5582\n",
      "\n",
      "median value in matrix_dataframe 0.0 mean value in matrix_dataframe 0.6567383990000523\n",
      "\n",
      "number of different values in matrix_dataframe is  1087 \n",
      "\n",
      "list of 10 most common values in matrix_dataframe is: \n",
      "1: the value 0 appeared 93754044 times (constitutes 81.39756% of the matrix values)\n",
      "2: the value 1 appeared 11152934 times (constitutes 9.68301% of the matrix values)\n",
      "3: the value 2 appeared 4170213 times (constitutes 3.62059% of the matrix values)\n",
      "4: the value 3 appeared 1993030 times (constitutes 1.73035% of the matrix values)\n",
      "5: the value 4 appeared 1100804 times (constitutes 0.95572% of the matrix values)\n",
      "6: the value 5 appeared 672858 times (constitutes 0.58418% of the matrix values)\n",
      "7: the value 6 appeared 444036 times (constitutes 0.38551% of the matrix values)\n",
      "8: the value 7 appeared 310903 times (constitutes 0.26993% of the matrix values)\n",
      "9: the value 8 appeared 227905 times (constitutes 0.19787% of the matrix values)\n",
      "10: the value 9 appeared 173612 times (constitutes 0.15073% of the matrix values)\n",
      "\n",
      "plotting a scatter plot of all values in matrix_dataframe (to see the distribution of values)\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "matrix_dataframe, mapping_between_old_and_new_indices = loadAndPreProcess.cut_empty_genes(matrix_dataframe)  #TODO: uncomment later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if wanted\n",
    "# print(f'\\note: this is the mapping_between_old_and_new_indices: \\n{mapping_between_old_and_new_indices}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_SingleValuePerImg -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gene_name = 'MKI67'\n",
    "custom_DS_SingleValuePerImg = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=imageFolder, \n",
    "                                                               matrix_dataframe=matrix_dataframe, \n",
    "                                                               features_dataframe=features_dataframe, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name)\n",
    "custom_DS_SingleValuePerImg_augmented = loadAndPreProcess.STDL_Dataset_SingleValuePerImg(imageFolder=augmentedImageFolder, \n",
    "                                                               matrix_dataframe=matrix_dataframe, \n",
    "                                                               features_dataframe=features_dataframe, \n",
    "                                                               barcodes_datafame=barcodes_datafame, \n",
    "                                                               chosen_gene_name=gene_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance -----\n",
      "calculate variance of all columns from  matrix_dataframe - and choosing K genes with higest variance ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "custom_DS_KGenesWithHighestVariance = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_KGenesWithHighestVariance_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_KGenesWithHighestVariance(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_NMF -----\n",
      "performing NMF decomposition on main matrix dataframe ...\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_LatentTensor -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "custom_DS_LatentTensor_NMF = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)\n",
    "custom_DS_LatentTensor_NMF_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_NMF(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "--delete-- verify inside STDL_Dataset_matrix_df_for_AE_init __init__: self.data.shape: (23073, 4992)\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.004043815657496452 max loss 1809.9281005859375\n",
      "               average loss 12.162598668217658\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.003786135232076049 max loss 1557.9254150390625\n",
      "               average loss 10.252500305712573\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00356870680116117 max loss 1534.355712890625\n",
      "               average loss 10.024925362803623\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n",
      "\n",
      "----- entering __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "initializing the autoencoder (this might take a while) ...\n",
      "\n",
      "----- entered function return_trained_AE_net -----\n",
      "--delete-- verify inside STDL_Dataset_matrix_df_for_AE_init __init__: self.data.shape: (23073, 4992)\n",
      "note - number of (hidden) linear layers is supposed to be 3\n",
      "\n",
      "entered __init__ of AutoencoderNet\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0032007612753659487 max loss 2818.077880859375\n",
      "               average loss 12.681916707772528\n",
      "\n",
      "iteration 2 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0037140692584216595 max loss 2754.62890625\n",
      "               average loss 11.750194375597756\n",
      "\n",
      "iteration 3 of 3 epochs\n",
      "batch 2000 of 2000 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0030109889339655638 max loss 2765.109375\n",
      "               average loss 9.842726948187337\n",
      "\n",
      "----- finished function return_trained_AE_net -----\n",
      "\n",
      "\n",
      "----- finished __init__ phase of  STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "\n",
    "k = 10\n",
    "custom_DS_LatentTensor_AE = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=imageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)\n",
    "custom_DS_LatentTensor_AE_augmented = loadAndPreProcess.STDL_Dataset_KValuesPerImg_LatentTensor_AutoEncoder(imageFolder=augmentedImageFolder, \n",
    "                                                                           matrix_dataframe=matrix_dataframe, \n",
    "                                                                           features_dataframe=features_dataframe, \n",
    "                                                                           barcodes_datafame=barcodes_datafame, \n",
    "                                                                           num_of_dims_k=k,\n",
    "                                                                           device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "display a few sample images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code to display some sample images\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check sizes of a pair (x,y) from all different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom_DS_SingleValuePerImg (single gene):      x shape torch.Size([3, 176, 176]), y is an int\n",
      "custom_DS_SingleValuePerImg_augmented:          x shape torch.Size([3, 176, 176]), y is an int\n",
      "---------\n",
      "custom_DS_KGenesWithHighestVariance:            x shape torch.Size([3, 176, 176]), y shape (10,)\n",
      "custom_DS_KGenesWithHighestVariance_augmented:  x shape torch.Size([3, 176, 176]), y shape (10,)\n",
      "---------\n",
      "custom_DS_LatentTensor_NMF:                     x shape torch.Size([3, 176, 176]), y shape (10,)\n",
      "custom_DS_LatentTensor_NMF_augmented:           x shape torch.Size([3, 176, 176]), y shape (10,)\n",
      "---------\n",
      "custom_DS_LatentTensor_AE:                      x shape torch.Size([3, 176, 176]), y shape torch.Size([10])\n",
      "custom_DS_LatentTensor_AE_augmented:            x shape torch.Size([3, 176, 176]), y shape torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(f'custom_DS_SingleValuePerImg (single gene):      x shape {custom_DS_SingleValuePerImg[0][0].shape}, y is an int')\n",
    "print(f'custom_DS_SingleValuePerImg_augmented:          x shape {custom_DS_SingleValuePerImg_augmented[0][0].shape}, y is an int')\n",
    "print(\"---------\")\n",
    "print(f'custom_DS_KGenesWithHighestVariance:            x shape {custom_DS_KGenesWithHighestVariance[0][0].shape}, y shape {custom_DS_KGenesWithHighestVariance[0][1].shape}')\n",
    "print(f'custom_DS_KGenesWithHighestVariance_augmented:  x shape {custom_DS_KGenesWithHighestVariance_augmented[0][0].shape}, y shape {custom_DS_KGenesWithHighestVariance_augmented[0][1].shape}')\n",
    "print(\"---------\")\n",
    "print(f'custom_DS_LatentTensor_NMF:                     x shape {custom_DS_LatentTensor_NMF[0][0].shape}, y shape {custom_DS_LatentTensor_NMF[0][1].shape}')\n",
    "print(f'custom_DS_LatentTensor_NMF_augmented:           x shape {custom_DS_LatentTensor_NMF_augmented[0][0].shape}, y shape {custom_DS_LatentTensor_NMF_augmented[0][1].shape}')\n",
    "print(\"---------\")\n",
    "print(f'custom_DS_LatentTensor_AE:                      x shape {custom_DS_LatentTensor_AE[0][0].shape}, y shape {custom_DS_LatentTensor_AE[0][1].shape}')\n",
    "print(f'custom_DS_LatentTensor_AE_augmented:            x shape {custom_DS_LatentTensor_AE_augmented[0][0].shape}, y shape {custom_DS_LatentTensor_AE_augmented[0][1].shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import executionModule\n",
    "\n",
    "# define hyperparameters for the experiments\n",
    "hyperparameters = dict()\n",
    "hyperparameters['batch_size'] = 25\n",
    "hyperparameters['max_alowed_number_of_batches'] = 99999\n",
    "hyperparameters['precent_of_dataset_allocated_for_training'] = 0.8\n",
    "hyperparameters['learning_rate'] = 1e-4\n",
    "hyperparameters['num_of_epochs'] = 5\n",
    "hyperparameters['channels'] = [32] \n",
    "hyperparameters['num_of_convolution_layers'] = len(hyperparameters['channels'])\n",
    "hyperparameters['hidden_dims'] = [100]\n",
    "hyperparameters['num_of_hidden_layers'] = len(hyperparameters['hidden_dims'])\n",
    "hyperparameters['pool_every'] = 99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 5\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "--delete-- verify batch_size 25\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 5 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00017852027667686343 max loss 517.2552490234375\n",
      "               average loss 4.624471161366616\n",
      "               number of correct predictions: 2797 / 3050\n",
      "\n",
      "iteration 2 of 5 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00019030160910915583 max loss 0.04110708087682724\n",
      "               average loss 0.0025523228639523026\n",
      "               number of correct predictions: 3044 / 3050\n",
      "\n",
      "iteration 3 of 5 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.00010590467718429863 max loss 0.04126758500933647\n",
      "               average loss 0.0022059201088029754\n",
      "               number of correct predictions: 3044 / 3050\n",
      "\n",
      "iteration 4 of 5 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 7.922844815766439e-05 max loss 0.040947917848825455\n",
      "               average loss 0.0018045733540631892\n",
      "               number of correct predictions: 3044 / 3050\n",
      "\n",
      "iteration 5 of 5 epochs\n",
      "batch 122 of 122 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 6.835432577645406e-05 max loss 0.03704729303717613\n",
      "               average loss 0.001753902866409187\n",
      "               number of correct predictions: 3044 / 3050\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_SingleValuePerImg, hyperparameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ * \\ ENTERED train_prediction_model / * \\ \n",
      "recieved model ConvNet(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=991232, out_features=100, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=100, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "recieved loss_fn MSELoss()\n",
      "recieved optimizer Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0\n",
      ")\n",
      "recieved num_of_epochs_wanted 5\n",
      "recieved max_alowed_number_of_batches 99999\n",
      "****** begin training ******\n",
      "\n",
      "iteration 1 of 5 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0023725370410829782 max loss 131.12777709960938\n",
      "               average loss 0.2896606674199336\n",
      "               number of correct predictions: 12003 / 12200\n",
      "\n",
      "iteration 2 of 5 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0018270215950906277 max loss 0.0384739451110363\n",
      "               average loss 0.003597692620117965\n",
      "               number of correct predictions: 12180 / 12200\n",
      "\n",
      "iteration 3 of 5 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.001244070241227746 max loss 0.03842104598879814\n",
      "               average loss 0.0030438752282414675\n",
      "               number of correct predictions: 12180 / 12200\n",
      "\n",
      "iteration 4 of 5 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0007406173390336335 max loss 0.038549479097127914\n",
      "               average loss 0.0025183832624518757\n",
      "               number of correct predictions: 12180 / 12200\n",
      "\n",
      "iteration 5 of 5 epochs\n",
      "batch 488 of 488 batches\n",
      "finished inner loop.\n",
      "\n",
      "in this epoch: min loss 0.0003772903874050826 max loss 0.03882228210568428\n",
      "               average loss 0.0021090132482998744\n",
      "               number of correct predictions: 12180 / 12200\n",
      "finished all epochs !\n",
      " \\ * / FINISHED train_prediction_model \\ * / \n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_SingleValuePerImg_augmented, hyperparameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "new() received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtuple\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtuple\u001b[0m, \u001b[31;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-fff664e788c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexecutionModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunExperimentWithModel_BasicConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_DS_KGenesWithHighestVariance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/STDLproject/executionModule.py\u001b[0m in \u001b[0;36mrunExperimentWithModel_BasicConvNet\u001b[0;34m(dataset, hyperparams, device)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# create the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'channels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pool_every'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyperparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hidden_dims'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;31m# create the loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/deepNetworkArchitechture.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_size, out_classes, channels, pool_every, hidden_dims)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/STDLproject/deepNetworkArchitechture.py\u001b[0m in \u001b[0;36m_make_classifier\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0mcurr_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_dims\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mM\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;31m# ========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/cs236781-hw/lib/python3.7/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, in_features, out_features, bias)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new() received an invalid combination of arguments - got (tuple, int), but expected one of:\n * (torch.device device)\n * (torch.Storage storage)\n * (Tensor other)\n * (tuple of ints size, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtuple\u001b[0m, \u001b[31;1mint\u001b[0m)\n * (object data, torch.device device)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mtuple\u001b[0m, \u001b[31;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_KGenesWithHighestVariance, hyperparameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "executionModule.runExperimentWithModel_BasicConvNet(custom_DS_KGenesWithHighestVariance_augmented, hyperparameters, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# executionModule.runExperiment1_singleGenePrediction(custom_DS_SingleValuePerImg, device)\n",
    "# executionModule.runExperiment1_singleGenePrediction(custom_DS_SingleValuePerImg_augmented, device)\n",
    "\n",
    "# executionModule.runExperiment2_allGenePrediction_dimReduction_KHighestVariances(custom_DS_KGenesWithHighestVariance, device)\n",
    "# executionModule.runExperiment2_allGenePrediction_dimReduction_KHighestVariances(custom_DS_KGenesWithHighestVariance_augmented, device)\n",
    "\n",
    "# executionModule.runTest3_allGenePrediction_dimReduction_NMF(stdl_ds2, device)\n",
    "# executionModule.runTest4_allGenePrediction_dimReduction_AutoEncoder(stdl_ds4, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
